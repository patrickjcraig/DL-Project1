{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from models.CNN import create_cnn_model\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(f):\n",
    "    # Move up one directory when loading the data\n",
    "    file_path = os.path.join('../../../', f)\n",
    "    return np.load(file_path)['arr_0']\n",
    "\n",
    "# Load the data\n",
    "X_train = load('kmnist-train-imgs.npz')/ 255.0\n",
    "x_test = load('kmnist-test-imgs.npz')/ 255.0\n",
    "Y_train = load('kmnist-train-labels.npz')\n",
    "y_test = load('kmnist-test-labels.npz')\n",
    "# Reshape the data for CNN input\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape and number of classes\n",
    "input_shape = X_train.shape[1:]  # 784 for KMNIST\n",
    "num_classes = Y_train.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing configuration: {'batch_normalization': False, 'pooling': 'max'}\n",
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.5087 - accuracy: 0.8361 - val_loss: 0.2364 - val_accuracy: 0.9225\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1852 - accuracy: 0.9436 - val_loss: 0.1487 - val_accuracy: 0.9517\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1260 - accuracy: 0.9624 - val_loss: 0.1391 - val_accuracy: 0.9530\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0960 - accuracy: 0.9707 - val_loss: 0.1136 - val_accuracy: 0.9642\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0759 - accuracy: 0.9762 - val_loss: 0.1117 - val_accuracy: 0.9642\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0598 - accuracy: 0.9811 - val_loss: 0.0958 - val_accuracy: 0.9707\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0474 - accuracy: 0.9840 - val_loss: 0.1042 - val_accuracy: 0.9695\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.1177 - val_accuracy: 0.9662\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 0.1213 - val_accuracy: 0.9657\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 0.1091 - val_accuracy: 0.9697\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "Testing configuration: {'batch_normalization': True, 'pooling': 'max'}\n",
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 10s 5ms/step - loss: 0.2064 - accuracy: 0.9439 - val_loss: 0.1300 - val_accuracy: 0.9610\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0673 - accuracy: 0.9803 - val_loss: 0.0661 - val_accuracy: 0.9798\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0465 - accuracy: 0.9858 - val_loss: 0.0793 - val_accuracy: 0.9742\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0329 - accuracy: 0.9897 - val_loss: 0.0639 - val_accuracy: 0.9797\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 0.0567 - val_accuracy: 0.9813\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.0678 - val_accuracy: 0.9783\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 13s 7ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.0699 - val_accuracy: 0.9797\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 0.0589 - val_accuracy: 0.9830\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0460 - val_accuracy: 0.9855\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.0527 - val_accuracy: 0.9868\n",
      "313/313 [==============================] - 1s 1ms/step\n",
      "Testing configuration: {'batch_normalization': False, 'pooling': 'avg'}\n",
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.6742 - accuracy: 0.7747 - val_loss: 0.3817 - val_accuracy: 0.8787\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2685 - accuracy: 0.9166 - val_loss: 0.2144 - val_accuracy: 0.9303\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.1861 - accuracy: 0.9420 - val_loss: 0.1872 - val_accuracy: 0.9407\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.1463 - accuracy: 0.9536 - val_loss: 0.1409 - val_accuracy: 0.9535\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1209 - accuracy: 0.9628 - val_loss: 0.1287 - val_accuracy: 0.9607\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.1026 - accuracy: 0.9670 - val_loss: 0.1261 - val_accuracy: 0.9610\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0865 - accuracy: 0.9727 - val_loss: 0.1401 - val_accuracy: 0.9558\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0764 - accuracy: 0.9754 - val_loss: 0.1028 - val_accuracy: 0.9703\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0668 - accuracy: 0.9785 - val_loss: 0.1023 - val_accuracy: 0.9682\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0560 - accuracy: 0.9817 - val_loss: 0.1007 - val_accuracy: 0.9692\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "Testing configuration: {'batch_normalization': True, 'pooling': 'avg'}\n",
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 10s 5ms/step - loss: 0.1956 - accuracy: 0.9483 - val_loss: 0.0812 - val_accuracy: 0.9755\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0649 - accuracy: 0.9810 - val_loss: 0.0657 - val_accuracy: 0.9805\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0455 - accuracy: 0.9863 - val_loss: 0.0954 - val_accuracy: 0.9680\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0353 - accuracy: 0.9891 - val_loss: 0.0501 - val_accuracy: 0.9840\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0281 - accuracy: 0.9913 - val_loss: 0.0391 - val_accuracy: 0.9887\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0438 - val_accuracy: 0.9873\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0352 - val_accuracy: 0.9895\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.0346 - val_accuracy: 0.9898\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0388 - val_accuracy: 0.9887\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.0522 - val_accuracy: 0.9848\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "Best configuration: {'batch_normalization': True, 'pooling': 'max'}\n",
      "Best accuracy: 0.9868333339691162\n",
      "Training best model on full training set...\n",
      "Epoch 1/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.2136 - accuracy: 0.9405 - val_loss: 0.1286 - val_accuracy: 0.9587\n",
      "Epoch 2/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0831 - accuracy: 0.9747 - val_loss: 0.0534 - val_accuracy: 0.9828\n",
      "Epoch 3/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0577 - accuracy: 0.9826 - val_loss: 0.0527 - val_accuracy: 0.9832\n",
      "Epoch 4/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0436 - accuracy: 0.9865 - val_loss: 0.0447 - val_accuracy: 0.9875\n",
      "Epoch 5/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 0.0406 - val_accuracy: 0.9870\n",
      "Epoch 6/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0311 - accuracy: 0.9901 - val_loss: 0.0405 - val_accuracy: 0.9892\n",
      "Epoch 7/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.0463 - val_accuracy: 0.9852\n",
      "Epoch 8/100\n",
      "3375/3375 [==============================] - 28s 8ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.0408 - val_accuracy: 0.9878\n",
      "Epoch 9/100\n",
      "3375/3375 [==============================] - 27s 8ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0410 - val_accuracy: 0.9868\n",
      "Epoch 10/100\n",
      "3375/3375 [==============================] - 26s 8ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0374 - val_accuracy: 0.9898\n",
      "Epoch 11/100\n",
      "3375/3375 [==============================] - 27s 8ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.0373 - val_accuracy: 0.9898\n",
      "Epoch 12/100\n",
      "3375/3375 [==============================] - 30s 9ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0344 - val_accuracy: 0.9908\n",
      "Epoch 13/100\n",
      "3375/3375 [==============================] - 25s 7ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0375 - val_accuracy: 0.9893\n",
      "Epoch 14/100\n",
      "3375/3375 [==============================] - 24s 7ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0341 - val_accuracy: 0.9913\n",
      "Epoch 15/100\n",
      "3375/3375 [==============================] - 28s 8ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.0392 - val_accuracy: 0.9893\n",
      "Epoch 16/100\n",
      "3375/3375 [==============================] - 28s 8ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0400 - val_accuracy: 0.9890\n",
      "Epoch 17/100\n",
      "3375/3375 [==============================] - 30s 9ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.0449 - val_accuracy: 0.9885\n",
      "Epoch 18/100\n",
      "3375/3375 [==============================] - 25s 7ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.0416 - val_accuracy: 0.9902\n",
      "Epoch 19/100\n",
      "3375/3375 [==============================] - 20s 6ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.0474 - val_accuracy: 0.9885\n",
      "Epoch 20/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.0411 - val_accuracy: 0.9902\n",
      "Epoch 21/100\n",
      "3375/3375 [==============================] - 20s 6ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.0389 - val_accuracy: 0.9898\n",
      "Epoch 22/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0085 - accuracy: 0.9967 - val_loss: 0.0333 - val_accuracy: 0.9912\n",
      "Epoch 23/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.0488 - val_accuracy: 0.9883\n",
      "Epoch 24/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0336 - val_accuracy: 0.9918\n",
      "Epoch 25/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0532 - val_accuracy: 0.9878\n",
      "Epoch 26/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0495 - val_accuracy: 0.9875\n",
      "Epoch 27/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.0466 - val_accuracy: 0.9890\n",
      "Epoch 28/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0361 - val_accuracy: 0.9915\n",
      "Epoch 29/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0380 - val_accuracy: 0.9922\n",
      "Epoch 30/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0458 - val_accuracy: 0.9900\n",
      "Epoch 31/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0418 - val_accuracy: 0.9910\n",
      "Epoch 32/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0460 - val_accuracy: 0.9903\n",
      "Test accuracy: 0.9692\n",
      "Test loss: 0.1575\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'num_layers': 3,\n",
    "    'filters': [32, 64, 64],\n",
    "    'kernel_sizes': [(3, 3), (3, 3), (3, 3)],\n",
    "    'activations': ['relu', 'relu', 'relu'],\n",
    "    'dense_units': 64,\n",
    "    'dense_activation': 'relu'\n",
    "}\n",
    "configs = [\n",
    "    {'batch_normalization': False, 'pooling': 'max'},\n",
    "    {'batch_normalization': True, 'pooling': 'max'},\n",
    "    {'batch_normalization': False, 'pooling': 'avg'},\n",
    "    {'batch_normalization': True, 'pooling': 'avg'}\n",
    "]\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "best_config = None\n",
    "best_accuracy = 0\n",
    "histories = []\n",
    "\n",
    "test_loss_df = pd.DataFrame()\n",
    "test_accuracy_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"Testing configuration: {config}\")\n",
    "    hyperparameters.update(config)\n",
    "    model = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs=10,\n",
    "                        batch_size=32,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping])\n",
    "    # Learning curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Learning Curve for Config: {config[\"pooling\"]} {config[\"batch_normalization\"]}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    now = datetime.datetime.now()\n",
    "    plt.savefig(f'learning_curve_{config[\"pooling\"]}_{config[\"batch_normalization\"]}_{now.strftime(\"%Y-%m-%d\")}.png')\n",
    "    plt.close()\n",
    "    # Append the last value of val_loss and val_accuracy an additional ten times\n",
    "    last_val_loss = history.history['val_loss'][-1]\n",
    "    last_val_accuracy = history.history['val_accuracy'][-1]\n",
    "    for _ in range(len(history.history['val_loss']), 100):\n",
    "        history.history['val_loss'].append(last_val_loss)\n",
    "        history.history['val_accuracy'].append(last_val_accuracy)\n",
    "    test_loss_df[f\"{config['pooling']} {config['batch_normalization']}\"] = history.history['val_loss']\n",
    "    test_accuracy_df[f\"{config['pooling']} {config['batch_normalization']}\"] = history.history['val_accuracy']\n",
    "\n",
    "\n",
    "    # Predictions on the validation set\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "    # Confusion matrix\n",
    "    confusion = confusion_matrix(y_test, y_pred_class)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion)\n",
    "    disp.plot()\n",
    "\n",
    "    plt.title(f'Confusion Matrix for Config: {config[\"pooling\"]} {config[\"batch_normalization\"]}')\n",
    "    plt.savefig(f'confusion_matrix_{config[\"pooling\"]}_{config[\"batch_normalization\"]}_{now.strftime(\"%Y-%m-%d\")}.png')\n",
    "    plt.close()\n",
    "    histories.append(history)\n",
    "    final_acc = history.history['val_accuracy'][-1]\n",
    "\n",
    "    if final_acc > best_accuracy:\n",
    "        best_accuracy = final_acc\n",
    "        best_config = config\n",
    "print(f\"Best configuration: {best_config}\")\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "# Train the best model on the full training set and evaluate on test set\n",
    "print(\"Training best model on full training set...\")\n",
    "hyperparameters = hyperparameters.copy()\n",
    "hyperparameters.update(best_config)\n",
    "\n",
    "# Create and compile the best model\n",
    "best_model = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "\n",
    "# Train on the full training set\n",
    "history = best_model.fit(x_train, y_train, \n",
    "                         epochs=100, \n",
    "                         batch_size=16, \n",
    "                         validation_data=(x_val, y_val),\n",
    "                         callbacks=[early_stopping],\n",
    "                         verbose=1)\n",
    "last_val_loss = history.history['val_loss'][-1]\n",
    "last_val_accuracy = history.history['val_accuracy'][-1]\n",
    "for _ in range(len(history.history['val_loss']), 100):\n",
    "    history.history['val_loss'].append(last_val_loss)\n",
    "    history.history['val_accuracy'].append(last_val_accuracy)\n",
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f'Learning Curve for Best Model: {best_config[\"pooling\"]} {best_config[\"batch_normalization\"]}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "now = datetime.datetime.now()\n",
    "plt.savefig(f'learning_curve_best_{best_config[\"pooling\"]}_{best_config[\"batch_normalization\"]}_{now.strftime(\"%Y-%m-%d\")}.png')\n",
    "plt.close()\n",
    "# Predictions on the test set\n",
    "y_pred = best_model.predict(x_test)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred_class)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion)\n",
    "disp.plot()\n",
    "plt.title(f'Confusion Matrix for Best Model: {best_config[\"pooling\"]} {best_config[\"batch_normalization\"]}')\n",
    "plt.savefig(f'confusion_matrix_best_{best_config[\"pooling\"]}_{best_config[\"batch_normalization\"]}_{now.strftime(\"%Y-%m-%d\")}.png')\n",
    "plt.close()\n",
    "# Add the \"best + config\" column\n",
    "test_loss_df[f\"best {best_config['pooling']} {best_config['batch_normalization']}\"] = history.history['val_loss']\n",
    "test_accuracy_df[f\"best {best_config['pooling']} {best_config['batch_normalization']}\"] = history.history['val_accuracy']\n",
    "\n",
    "# Save the dataframes to CSV files\n",
    "test_loss_df.to_csv('test_loss.csv', index=False)\n",
    "test_accuracy_df.to_csv('test_accuracy.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hyperparameters.json', 'w') as f:\n",
    "    json.dump(hyperparameters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout(image, mask_size=16):\n",
    "    \"\"\"Applies Cutout augmentation to an image.\"\"\"\n",
    "    h, w, _ = image.shape\n",
    "    x = np.random.randint(0, w)\n",
    "    y = np.random.randint(0, h)\n",
    "\n",
    "    # Ensure the cutout does not go out of bounds\n",
    "    x1 = np.clip(x - mask_size // 2, 0, w)\n",
    "    x2 = np.clip(x + mask_size // 2, 0, w)\n",
    "    y1 = np.clip(y - mask_size // 2, 0, h)\n",
    "    y2 = np.clip(y + mask_size // 2, 0, h)\n",
    "\n",
    "    # Create a copy of the image to avoid modifying the original\n",
    "    image_copy = image.copy()\n",
    "    image_copy[y1:y2, x1:x2, :] = 0  # Set the cutout region to black\n",
    "\n",
    "    return image_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_layers': 3, 'filters': [32, 64, 64], 'kernel_sizes': [[3, 3], [3, 3], [3, 3]], 'activations': ['relu', 'relu', 'relu'], 'dense_units': 64, 'dense_activation': 'relu', 'batch_normalization': True, 'pooling': 'avg'}\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1963 - accuracy: 0.9473 - val_loss: 0.0956 - val_accuracy: 0.9685\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0700 - accuracy: 0.9792 - val_loss: 0.0603 - val_accuracy: 0.9827\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0469 - accuracy: 0.9859 - val_loss: 0.0517 - val_accuracy: 0.9817\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0405 - accuracy: 0.9873 - val_loss: 0.0437 - val_accuracy: 0.9868\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.0539 - val_accuracy: 0.9830\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0270 - accuracy: 0.9918 - val_loss: 0.0376 - val_accuracy: 0.9897\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 0.0404 - val_accuracy: 0.9880\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0423 - val_accuracy: 0.9880\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0383 - val_accuracy: 0.9900\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0396 - val_accuracy: 0.9880\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0468 - val_accuracy: 0.9885\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0356 - val_accuracy: 0.9903\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0327 - val_accuracy: 0.9913\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.0396 - val_accuracy: 0.9888\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0378 - val_accuracy: 0.9898\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.1965 - accuracy: 0.9486 - val_loss: 0.2134 - val_accuracy: 0.9262\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0676 - accuracy: 0.9799 - val_loss: 0.0632 - val_accuracy: 0.9808\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0485 - accuracy: 0.9849 - val_loss: 0.0750 - val_accuracy: 0.9775\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0355 - accuracy: 0.9891 - val_loss: 0.0419 - val_accuracy: 0.9880\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.0646 - val_accuracy: 0.9788\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.0428 - val_accuracy: 0.9883\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0458 - val_accuracy: 0.9872\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0520 - val_accuracy: 0.9857\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0162 - accuracy: 0.9943 - val_loss: 0.0553 - val_accuracy: 0.9858\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0447 - val_accuracy: 0.9882\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0408 - val_accuracy: 0.9892\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0435 - val_accuracy: 0.9878\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0371 - val_accuracy: 0.9902\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0395 - val_accuracy: 0.9905\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0381 - val_accuracy: 0.9895\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.4931 - accuracy: 0.8508 - val_loss: 0.4760 - val_accuracy: 0.8453\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2212 - accuracy: 0.9314 - val_loss: 0.2596 - val_accuracy: 0.9150\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1703 - accuracy: 0.9466 - val_loss: 0.2252 - val_accuracy: 0.9265\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1432 - accuracy: 0.9554 - val_loss: 0.1832 - val_accuracy: 0.9428\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1219 - accuracy: 0.9608 - val_loss: 0.1059 - val_accuracy: 0.9680\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1122 - accuracy: 0.9658 - val_loss: 0.1185 - val_accuracy: 0.9650\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1042 - accuracy: 0.9673 - val_loss: 0.1422 - val_accuracy: 0.9568\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0946 - accuracy: 0.9709 - val_loss: 0.1196 - val_accuracy: 0.9647\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0861 - accuracy: 0.9734 - val_loss: 0.1603 - val_accuracy: 0.9517\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0822 - accuracy: 0.9736 - val_loss: 0.1076 - val_accuracy: 0.9672\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0785 - accuracy: 0.9749 - val_loss: 0.0845 - val_accuracy: 0.9753\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0723 - accuracy: 0.9776 - val_loss: 0.0972 - val_accuracy: 0.9693\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0707 - accuracy: 0.9771 - val_loss: 0.0920 - val_accuracy: 0.9723\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0695 - accuracy: 0.9779 - val_loss: 0.0799 - val_accuracy: 0.9777\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0626 - accuracy: 0.9805 - val_loss: 0.1149 - val_accuracy: 0.9657\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2027 - accuracy: 0.9449 - val_loss: 0.1071 - val_accuracy: 0.9672\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0743 - accuracy: 0.9780 - val_loss: 0.0726 - val_accuracy: 0.9788\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0526 - accuracy: 0.9843 - val_loss: 0.0628 - val_accuracy: 0.9818\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0440 - accuracy: 0.9863 - val_loss: 0.0479 - val_accuracy: 0.9867\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.0499 - val_accuracy: 0.9852\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0283 - accuracy: 0.9911 - val_loss: 0.0347 - val_accuracy: 0.9902\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.0344 - val_accuracy: 0.9890\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 0.0418 - val_accuracy: 0.9875\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0638 - val_accuracy: 0.9815\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.0443 - val_accuracy: 0.9882\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.0335 - val_accuracy: 0.9903\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0627 - val_accuracy: 0.9838\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0330 - val_accuracy: 0.9908\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0439 - val_accuracy: 0.9888\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0462 - val_accuracy: 0.9885\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.4530 - accuracy: 0.8600 - val_loss: 0.0945 - val_accuracy: 0.9707\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2316 - accuracy: 0.9260 - val_loss: 0.1051 - val_accuracy: 0.9693\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1934 - accuracy: 0.9377 - val_loss: 0.0597 - val_accuracy: 0.9792\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.1695 - accuracy: 0.9454 - val_loss: 0.0512 - val_accuracy: 0.9845\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1527 - accuracy: 0.9502 - val_loss: 0.0508 - val_accuracy: 0.9825\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1415 - accuracy: 0.9538 - val_loss: 0.0563 - val_accuracy: 0.9820\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1264 - accuracy: 0.9593 - val_loss: 0.0526 - val_accuracy: 0.9825\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1224 - accuracy: 0.9594 - val_loss: 0.0372 - val_accuracy: 0.9892\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1176 - accuracy: 0.9610 - val_loss: 0.0306 - val_accuracy: 0.9902\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1109 - accuracy: 0.9629 - val_loss: 0.0303 - val_accuracy: 0.9910\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1043 - accuracy: 0.9667 - val_loss: 0.0444 - val_accuracy: 0.9872\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1007 - accuracy: 0.9666 - val_loss: 0.0335 - val_accuracy: 0.9907\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0989 - accuracy: 0.9677 - val_loss: 0.0333 - val_accuracy: 0.9908\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0943 - accuracy: 0.9689 - val_loss: 0.0317 - val_accuracy: 0.9907\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0937 - accuracy: 0.9702 - val_loss: 0.0324 - val_accuracy: 0.9913\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.2142 - accuracy: 0.9411 - val_loss: 0.1341 - val_accuracy: 0.9570\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0808 - accuracy: 0.9766 - val_loss: 0.0613 - val_accuracy: 0.9835\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0583 - accuracy: 0.9826 - val_loss: 0.0592 - val_accuracy: 0.9842\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0480 - accuracy: 0.9850 - val_loss: 0.0418 - val_accuracy: 0.9873\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.0553 - val_accuracy: 0.9833\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0322 - accuracy: 0.9900 - val_loss: 0.0325 - val_accuracy: 0.9913\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.0324 - val_accuracy: 0.9918\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.0458 - val_accuracy: 0.9863\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0221 - accuracy: 0.9931 - val_loss: 0.0445 - val_accuracy: 0.9867\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.0300 - val_accuracy: 0.9908\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0336 - val_accuracy: 0.9910\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0311 - val_accuracy: 0.9920\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.0300 - val_accuracy: 0.9913\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.0351 - val_accuracy: 0.9910\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0331 - val_accuracy: 0.9902\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 10s 5ms/step - loss: 0.1946 - accuracy: 0.9469 - val_loss: 0.0766 - val_accuracy: 0.9775\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0674 - accuracy: 0.9802 - val_loss: 0.1005 - val_accuracy: 0.9683\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0461 - accuracy: 0.9862 - val_loss: 0.0664 - val_accuracy: 0.9775\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0354 - accuracy: 0.9890 - val_loss: 0.0619 - val_accuracy: 0.9815\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 0.0470 - val_accuracy: 0.9865\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0532 - val_accuracy: 0.9832\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.0411 - val_accuracy: 0.9882\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.0361 - val_accuracy: 0.9892\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.0435 - val_accuracy: 0.9862\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0534 - val_accuracy: 0.9848\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.0416 - val_accuracy: 0.9877\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0882 - val_accuracy: 0.9777\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0335 - val_accuracy: 0.9907\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 0.0339 - val_accuracy: 0.9912\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0362 - val_accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "# Load the hyperparameters\n",
    "hyperparameters = json.load(open('hyperparameters.json'))\n",
    "print(hyperparameters)\n",
    "# Create the models with different noise injection\n",
    "best_model_rand_noise = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "best_model_radial_noise = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "best_model_flip = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "best_model_zoom = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "best_model_mask = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "best_model_rand_noise_zoom = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "best_model_no_noise = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "\n",
    "# Random noise\n",
    "datagen_rand_noise = ImageDataGenerator(\n",
    "    preprocessing_function=lambda x: np.clip(x + np.random.normal(0, 0.1, x.shape), 0, 1)  # Noise injection\n",
    ")\n",
    "\n",
    "# Radial noise\n",
    "datagen_radial_noise = ImageDataGenerator(\n",
    "    preprocessing_function=lambda x: np.clip(x + np.random.normal(0, 0.1, x.shape) * np.sqrt(np.sum(np.square(np.indices(x.shape[1:3]).T - np.array(x.shape[1:3])/2), axis=2)).reshape(1, x.shape[1], x.shape[2], 1) / np.max(np.sqrt(np.sum(np.square(np.indices(x.shape[1:3]).T - np.array(x.shape[1:3])/2), axis=2))), 0, 1)  # Radial noise injection\n",
    ")\n",
    "\n",
    "# Flip\n",
    "datagen_flip = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "# Zoom\n",
    "datagen_zoom = ImageDataGenerator(\n",
    "    zoom_range=0.1 # Zoom in on the image\n",
    ")\n",
    "\n",
    "# Mask\n",
    "datagen_mask = ImageDataGenerator(\n",
    "    preprocessing_function = lambda x: cutout(x, mask_size=16) # Zoom in on the image\n",
    ")\n",
    "datagen_rand_noise_zoom = ImageDataGenerator(\n",
    "    preprocessing_function=lambda x: np.clip(x + np.random.normal(0, 0.1, x.shape), 0, 1),  # Noise injection\n",
    "    zoom_range=0.1 # Zoom in on the image\n",
    ")\n",
    "# No noise\n",
    "datagen_no_noise = ImageDataGenerator()\n",
    "\n",
    "datagen_val = ImageDataGenerator()\n",
    "# Wrap the datagen with our custom generator\n",
    "train_generator_rand_noise = datagen_rand_noise.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_radial_noise = datagen_radial_noise.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_flip = datagen_flip.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_zoom = datagen_zoom.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_mask = datagen_mask.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_rand_noise_zoom = datagen_rand_noise_zoom.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_no_noise = datagen_no_noise.flow(x_train, y_train, batch_size=32)\n",
    "val_generator = datagen_val.flow(x_val, y_val, batch_size=32)\n",
    "# Train the model with custom augmentation\n",
    "augmentation_loss_df = pd.DataFrame()\n",
    "augmentation_accuracy_df = pd.DataFrame()\n",
    "\n",
    "# Random noise\n",
    "history_rand_noise = best_model_rand_noise.fit(train_generator_rand_noise,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,  \n",
    "                        verbose=1\n",
    "                        )\n",
    "augmentation_loss_df[f\"rand_noise\"] = history_rand_noise.history['val_loss']\n",
    "augmentation_accuracy_df[f\"rand_noise\"] = history_rand_noise.history['val_accuracy']\n",
    "\n",
    "# Radial noise\n",
    "history_radial_noise = best_model_radial_noise.fit(train_generator_radial_noise,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,  \n",
    "                        verbose=1\n",
    "                        )\n",
    "augmentation_loss_df[f\"radial_noise\"] = history_radial_noise.history['val_loss']\n",
    "augmentation_accuracy_df[f\"radial_noise\"] = history_radial_noise.history['val_accuracy']\n",
    "\n",
    "\n",
    "# Flip\n",
    "history_flip = best_model_flip.fit(train_generator_flip,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1\n",
    "                        )\n",
    "augmentation_loss_df[f\"flip\"] = history_flip.history['val_loss']\n",
    "augmentation_accuracy_df[f\"flip\"] = history_flip.history['val_accuracy']\n",
    "\n",
    "# Zoom\n",
    "history_zoom = best_model_zoom.fit(train_generator_zoom,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1\n",
    "                        )\n",
    "augmentation_loss_df[f\"zoom\"] = history_zoom.history['val_loss']\n",
    "augmentation_accuracy_df[f\"zoom\"] = history_zoom.history['val_accuracy']\n",
    "\n",
    "# Mask\n",
    "history_mask = best_model_mask.fit(train_generator_mask,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1\n",
    "                        )\n",
    "augmentation_loss_df[f\"mask\"] = history_mask.history['val_loss']\n",
    "augmentation_accuracy_df[f\"mask\"] = history_mask.history['val_accuracy']\n",
    "\n",
    "# Rand noise and zoom\n",
    "history_rand_noise_zoom = best_model_rand_noise_zoom.fit(train_generator_rand_noise_zoom,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1\n",
    "                        )\n",
    "augmentation_loss_df[f\"rand_noise_zoom\"] = history_rand_noise_zoom.history['val_loss']\n",
    "augmentation_accuracy_df[f\"rand_noise_zoom\"] = history_rand_noise_zoom.history['val_accuracy']\n",
    "\n",
    "# No noise\n",
    "history_no_noise = best_model_no_noise.fit(train_generator_no_noise,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1\n",
    "                        )\n",
    "augmentation_loss_df[f\"no_noise\"] = history_no_noise.history['val_loss']\n",
    "augmentation_accuracy_df[f\"no_noise\"] = history_no_noise.history['val_accuracy']\n",
    "\n",
    "augmentation_loss_df.to_csv('augmentation_loss.csv', index=False)\n",
    "augmentation_accuracy_df.to_csv('augmentation_accuracy.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand noise test accuracy: 0.9705\n",
      "Rand noise test loss: 0.1497\n",
      "Radial noise test accuracy: 0.9721\n",
      "Radial noise test loss: 0.1365\n",
      "Flip test accuracy: 0.9229\n",
      "Flip test loss: 0.2834\n",
      "Zoom test accuracy: 0.9672\n",
      "Zoom test loss: 0.1553\n",
      "Mask test accuracy: 0.9626\n",
      "Mask test loss: 0.1412\n",
      "Rand noise and zoom test accuracy: 0.9667\n",
      "Rand noise and zoom test loss: 0.1692\n",
      "No noise test accuracy: 0.9665\n",
      "No noise test loss: 0.1730\n"
     ]
    }
   ],
   "source": [
    "rand_noise_loss, rand_noise_accuracy = best_model_rand_noise.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Rand noise test accuracy: {rand_noise_accuracy:.4f}\")\n",
    "print(f\"Rand noise test loss: {rand_noise_loss:.4f}\")\n",
    "radial_noise_loss, radial_noise_accuracy = best_model_radial_noise.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Radial noise test accuracy: {radial_noise_accuracy:.4f}\")\n",
    "print(f\"Radial noise test loss: {radial_noise_loss:.4f}\")\n",
    "flip_loss, flip_accuracy = best_model_flip.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Flip test accuracy: {flip_accuracy:.4f}\")\n",
    "print(f\"Flip test loss: {flip_loss:.4f}\")\n",
    "zoom_loss, zoom_accuracy = best_model_zoom.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Zoom test accuracy: {zoom_accuracy:.4f}\")\n",
    "print(f\"Zoom test loss: {zoom_loss:.4f}\")\n",
    "mask_loss, mask_accuracy = best_model_mask.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Mask test accuracy: {mask_accuracy:.4f}\")\n",
    "print(f\"Mask test loss: {mask_loss:.4f}\")\n",
    "rand_noise_zoom_loss, rand_noise_zoom_accuracy = best_model_rand_noise_zoom.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Rand noise and zoom test accuracy: {rand_noise_zoom_accuracy:.4f}\")\n",
    "print(f\"Rand noise and zoom test loss: {rand_noise_zoom_loss:.4f}\")\n",
    "no_noise_loss, no_noise_accuracy = best_model_no_noise.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"No noise test accuracy: {no_noise_accuracy:.4f}\")\n",
    "print(f\"No noise test loss: {no_noise_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 1ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 1ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# List of models and their names\n",
    "models = [\n",
    "    (best_model_rand_noise, \"Random Noise\"),\n",
    "    (best_model_radial_noise, \"Radial Noise\"),\n",
    "    (best_model_flip, \"Flip\"),\n",
    "    (best_model_zoom, \"Zoom\"),\n",
    "    (best_model_mask, \"Mask\"),\n",
    "    (best_model_rand_noise_zoom, \"Random Noise + Zoom\"),\n",
    "    (best_model_no_noise, \"No Noise\")\n",
    "]\n",
    "\n",
    "# Create and save confusion matrices for each model\n",
    "for model, name in models:\n",
    "    # Predictions on the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Confusion matrix\n",
    "    confusion = confusion_matrix(y_test, y_pred_class)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    disp.plot(ax=ax)\n",
    "    plt.title(f'Confusion Matrix for {name}')\n",
    "    \n",
    "    # Save the figure\n",
    "    now = datetime.datetime.now()\n",
    "    plt.savefig(f'confusion_matrix_{name.replace(\" \", \"_\").lower()}_{now.strftime(\"%Y-%m-%d\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
