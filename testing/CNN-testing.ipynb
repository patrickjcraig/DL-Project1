{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from models.CNN import create_cnn_model\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(f):\n",
    "    # Move up one directory when loading the data\n",
    "    file_path = os.path.join('../../../', f)\n",
    "    return np.load(file_path)['arr_0']\n",
    "\n",
    "# Load the data\n",
    "X_train = load('kmnist-train-imgs.npz')/255.0\n",
    "x_test = load('kmnist-test-imgs.npz')/255.0\n",
    "Y_train = load('kmnist-train-labels.npz')\n",
    "y_test = load('kmnist-test-labels.npz')\n",
    "# Reshape the data for CNN input\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape and number of classes\n",
    "input_shape = X_train.shape[1:]  # 784 for KMNIST\n",
    "num_classes = Y_train.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing configuration: {'batch_normalization': False, 'pooling': 'max'}\n",
      "Epoch 1/20\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.4911 - accuracy: 0.8421 - val_loss: 0.2453 - val_accuracy: 0.9215\n",
      "Epoch 2/20\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1757 - accuracy: 0.9455 - val_loss: 0.1625 - val_accuracy: 0.9467\n",
      "Epoch 3/20\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1200 - accuracy: 0.9631 - val_loss: 0.1319 - val_accuracy: 0.9593\n",
      "Epoch 4/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0912 - accuracy: 0.9715 - val_loss: 0.1222 - val_accuracy: 0.9615\n",
      "Epoch 5/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0696 - accuracy: 0.9779 - val_loss: 0.1241 - val_accuracy: 0.9622\n",
      "Epoch 6/20\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0546 - accuracy: 0.9818 - val_loss: 0.0990 - val_accuracy: 0.9707\n",
      "Epoch 7/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0427 - accuracy: 0.9861 - val_loss: 0.1041 - val_accuracy: 0.9692\n",
      "Epoch 8/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 0.1223 - val_accuracy: 0.9695\n",
      "Epoch 9/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0301 - accuracy: 0.9904 - val_loss: 0.1018 - val_accuracy: 0.9740\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "Testing configuration: {'batch_normalization': True, 'pooling': 'max'}\n",
      "Epoch 1/20\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2146 - accuracy: 0.9421 - val_loss: 0.1013 - val_accuracy: 0.9692\n",
      "Epoch 2/20\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0702 - accuracy: 0.9795 - val_loss: 0.0660 - val_accuracy: 0.9787\n",
      "Epoch 3/20\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0478 - accuracy: 0.9854 - val_loss: 0.0700 - val_accuracy: 0.9773\n",
      "Epoch 4/20\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0338 - accuracy: 0.9899 - val_loss: 0.0664 - val_accuracy: 0.9808\n",
      "Epoch 5/20\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.0831 - val_accuracy: 0.9752\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "Testing configuration: {'batch_normalization': False, 'pooling': 'avg'}\n",
      "Epoch 1/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.6473 - accuracy: 0.7879 - val_loss: 0.3415 - val_accuracy: 0.8885\n",
      "Epoch 2/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2587 - accuracy: 0.9183 - val_loss: 0.2265 - val_accuracy: 0.9290\n",
      "Epoch 3/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.1791 - accuracy: 0.9437 - val_loss: 0.1768 - val_accuracy: 0.9430\n",
      "Epoch 4/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.1445 - accuracy: 0.9542 - val_loss: 0.1378 - val_accuracy: 0.9567\n",
      "Epoch 5/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.1182 - accuracy: 0.9638 - val_loss: 0.1264 - val_accuracy: 0.9600\n",
      "Epoch 6/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.1018 - accuracy: 0.9682 - val_loss: 0.1197 - val_accuracy: 0.9620\n",
      "Epoch 7/20\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0879 - accuracy: 0.9728 - val_loss: 0.1182 - val_accuracy: 0.9615\n",
      "Epoch 8/20\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0769 - accuracy: 0.9754 - val_loss: 0.1300 - val_accuracy: 0.9580\n",
      "Epoch 9/20\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0638 - accuracy: 0.9797 - val_loss: 0.1016 - val_accuracy: 0.9677\n",
      "Epoch 10/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 0.1068 - val_accuracy: 0.9673\n",
      "Epoch 11/20\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0498 - accuracy: 0.9840 - val_loss: 0.1049 - val_accuracy: 0.9672\n",
      "Epoch 12/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0452 - accuracy: 0.9849 - val_loss: 0.1004 - val_accuracy: 0.9728\n",
      "Epoch 13/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.1034 - val_accuracy: 0.9700\n",
      "Epoch 14/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 0.1165 - val_accuracy: 0.9663\n",
      "Epoch 15/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0312 - accuracy: 0.9897 - val_loss: 0.1113 - val_accuracy: 0.9688\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "Testing configuration: {'batch_normalization': True, 'pooling': 'avg'}\n",
      "Epoch 1/20\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1917 - accuracy: 0.9483 - val_loss: 0.1443 - val_accuracy: 0.9557\n",
      "Epoch 2/20\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0661 - accuracy: 0.9809 - val_loss: 0.0630 - val_accuracy: 0.9822\n",
      "Epoch 3/20\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0482 - accuracy: 0.9854 - val_loss: 0.0597 - val_accuracy: 0.9800\n",
      "Epoch 4/20\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0348 - accuracy: 0.9892 - val_loss: 0.0559 - val_accuracy: 0.9823\n",
      "Epoch 5/20\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0510 - val_accuracy: 0.9853\n",
      "Epoch 6/20\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0401 - val_accuracy: 0.9872\n",
      "Epoch 7/20\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.0456 - val_accuracy: 0.9863\n",
      "Epoch 8/20\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.0503 - val_accuracy: 0.9838\n",
      "Epoch 9/20\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.0466 - val_accuracy: 0.9857\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "Best configuration: {'batch_normalization': True, 'pooling': 'avg'}\n",
      "Best accuracy: 0.9871666431427002\n",
      "Training best model on full training set...\n",
      "Epoch 1/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.2050 - accuracy: 0.9421 - val_loss: 0.1101 - val_accuracy: 0.9662\n",
      "Epoch 2/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0799 - accuracy: 0.9764 - val_loss: 0.0590 - val_accuracy: 0.9823\n",
      "Epoch 3/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0560 - accuracy: 0.9828 - val_loss: 0.0468 - val_accuracy: 0.9860\n",
      "Epoch 4/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0447 - accuracy: 0.9862 - val_loss: 0.0415 - val_accuracy: 0.9875\n",
      "Epoch 5/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 0.0302 - val_accuracy: 0.9895\n",
      "Epoch 6/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0323 - accuracy: 0.9904 - val_loss: 0.0305 - val_accuracy: 0.9918\n",
      "Epoch 7/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0265 - accuracy: 0.9919 - val_loss: 0.0336 - val_accuracy: 0.9905\n",
      "Epoch 8/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0412 - val_accuracy: 0.9883\n",
      "Epoch 9/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0433 - val_accuracy: 0.9877\n",
      "Epoch 10/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.0320 - val_accuracy: 0.9920\n",
      "Epoch 11/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.0277 - val_accuracy: 0.9927\n",
      "Epoch 12/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.0279 - val_accuracy: 0.9930\n",
      "Epoch 13/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0331 - val_accuracy: 0.9922\n",
      "Epoch 14/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0334 - val_accuracy: 0.9913\n",
      "Epoch 15/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.0391 - val_accuracy: 0.9907\n",
      "Epoch 16/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.0399 - val_accuracy: 0.9900\n",
      "Epoch 17/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0348 - val_accuracy: 0.9910\n",
      "Epoch 18/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0294 - val_accuracy: 0.9928\n",
      "Epoch 19/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0355 - val_accuracy: 0.9928\n",
      "Epoch 20/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0308 - val_accuracy: 0.9908\n",
      "Epoch 21/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0359 - val_accuracy: 0.9907\n",
      "Test accuracy: 0.9700\n",
      "Test loss: 0.1298\n",
      "313/313 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'num_layers': 3,\n",
    "    'filters': [32, 64, 64],\n",
    "    'kernel_sizes': [(3, 3), (3, 3), (3, 3)],\n",
    "    'activations': ['relu', 'relu', 'relu'],\n",
    "    'dense_units': 64,\n",
    "    'dense_activation': 'relu'\n",
    "}\n",
    "configs = [\n",
    "    {'batch_normalization': False, 'pooling': 'max'},\n",
    "    {'batch_normalization': True, 'pooling': 'max'},\n",
    "    {'batch_normalization': False, 'pooling': 'avg'},\n",
    "    {'batch_normalization': True, 'pooling': 'avg'}\n",
    "]\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "best_config = None\n",
    "best_accuracy = 0\n",
    "histories = []\n",
    "\n",
    "test_loss_df = pd.DataFrame()\n",
    "test_accuracy_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"Testing configuration: {config}\")\n",
    "    hyperparameters.update(config)\n",
    "    model = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs=20,\n",
    "                        batch_size=32,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping])\n",
    "    # Learning curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Learning Curve for Config: {config[\"pooling\"]} {config[\"batch_normalization\"]}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    now = datetime.datetime.now()\n",
    "    plt.savefig(f'learning_curve_{config[\"pooling\"]}_{config[\"batch_normalization\"]}_{now.strftime(\"%Y-%m-%d\")}.png')\n",
    "    plt.close()\n",
    "    # Append the last value of val_loss and val_accuracy an additional ten times\n",
    "    last_val_loss = history.history['val_loss'][-1]\n",
    "    last_val_accuracy = history.history['val_accuracy'][-1]\n",
    "    for _ in range(len(history.history['val_loss']), 100):\n",
    "        history.history['val_loss'].append(last_val_loss)\n",
    "        history.history['val_accuracy'].append(last_val_accuracy)\n",
    "    test_loss_df[f\"{config['pooling']} {config['batch_normalization']}\"] = history.history['val_loss']\n",
    "    test_accuracy_df[f\"{config['pooling']} {config['batch_normalization']}\"] = history.history['val_accuracy']\n",
    "\n",
    "\n",
    "    # Predictions on the validation set\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "    # Confusion matrix\n",
    "    confusion = confusion_matrix(y_test, y_pred_class)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion)\n",
    "    disp.plot()\n",
    "\n",
    "    plt.title(f'Confusion Matrix for Config: {config[\"pooling\"]} {config[\"batch_normalization\"]}')\n",
    "    plt.savefig(f'confusion_matrix_{config[\"pooling\"]}_{config[\"batch_normalization\"]}_{now.strftime(\"%Y-%m-%d\")}.png')\n",
    "    plt.close()\n",
    "    histories.append(history)\n",
    "    final_acc = max(history.history['val_accuracy'])\n",
    "\n",
    "    if final_acc > best_accuracy:\n",
    "        best_accuracy = final_acc\n",
    "        best_config = config\n",
    "print(f\"Best configuration: {best_config}\")\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "# Train the best model on the full training set and evaluate on test set\n",
    "print(\"Training best model on full training set...\")\n",
    "hyperparameters = hyperparameters.copy()\n",
    "hyperparameters.update(best_config)\n",
    "\n",
    "# Create and compile the best model\n",
    "best_model = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# Train on the full training set\n",
    "history = best_model.fit(x_train, y_train, \n",
    "                         epochs=100, \n",
    "                         batch_size=16, \n",
    "                         validation_data=(x_val, y_val),\n",
    "                         callbacks=[early_stopping],\n",
    "                         verbose=1)\n",
    "# Append the last value of val_loss and val_accuracy an additional # of times so it can be plotted on same graph as other models\n",
    "last_val_loss = history.history['val_loss'][-1]\n",
    "last_val_accuracy = history.history['val_accuracy'][-1]\n",
    "for _ in range(len(history.history['val_loss']), 100):\n",
    "    history.history['val_loss'].append(last_val_loss)\n",
    "    history.history['val_accuracy'].append(last_val_accuracy)\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Plot the learnin curve of the best model\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f'Learning Curve for Best Model: {best_config[\"pooling\"]} {best_config[\"batch_normalization\"]}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "now = datetime.datetime.now()\n",
    "plt.savefig(f'learning_curve_best_{best_config[\"pooling\"]}_{best_config[\"batch_normalization\"]}_{now.strftime(\"%Y-%m-%d\")}.png')\n",
    "plt.close()\n",
    "# Predictions on the test set\n",
    "y_pred = best_model.predict(x_test)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred_class)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion)\n",
    "disp.plot()\n",
    "plt.title(f'Confusion Matrix for Best Model: {best_config[\"pooling\"]} {best_config[\"batch_normalization\"]}')\n",
    "plt.savefig(f'confusion_matrix_best_{best_config[\"pooling\"]}_{best_config[\"batch_normalization\"]}_{now.strftime(\"%Y-%m-%d\")}.png')\n",
    "plt.close()\n",
    "# Add the \"best + config\" column\n",
    "test_loss_df[f\"best {best_config['pooling']} {best_config['batch_normalization']}\"] = history.history['val_loss']\n",
    "test_accuracy_df[f\"best {best_config['pooling']} {best_config['batch_normalization']}\"] = history.history['val_accuracy']\n",
    "\n",
    "# Save the dataframes to CSV files\n",
    "test_loss_df.to_csv('test_loss.csv', index=False)\n",
    "test_accuracy_df.to_csv('test_accuracy.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9871666431427002\n"
     ]
    }
   ],
   "source": [
    "print(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hyperparameters.json', 'w') as f:\n",
    "    json.dump(hyperparameters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout(image, mask_size=16, num_cutouts=1):\n",
    "    \"\"\"Applies Cutout augmentation to an image.\"\"\"\n",
    "    h, w, _ = image.shape\n",
    "    image_copy = image.copy()\n",
    "\n",
    "    for _ in range(num_cutouts):\n",
    "        x = np.random.randint(0, w)\n",
    "        y = np.random.randint(0, h)\n",
    "\n",
    "        # Ensure the cutout does not go out of bounds\n",
    "        x1 = np.clip(x - mask_size // 2, 0, w)\n",
    "        x2 = np.clip(x + mask_size // 2, 0, w)\n",
    "        y1 = np.clip(y - mask_size // 2, 0, h)\n",
    "        y2 = np.clip(y + mask_size // 2, 0, h)\n",
    "\n",
    "        # Set the cutout region to the mean value of the image\n",
    "        mask_color = np.mean(image_copy)\n",
    "        image_copy[y1:y2, x1:x2, :] = mask_color\n",
    "\n",
    "    return image_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random noise\n",
    "def add_random_noise(image, noise_factor=0.1):\n",
    "    \"\"\"Adds random noise to an image.\"\"\"\n",
    "    noisy_image = image + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=image.shape)\n",
    "    return np.clip(noisy_image, 0.0, 1.0)\n",
    "\n",
    "def add_radial_noise(image, noise_factor=0.1):\n",
    "    \"\"\"Adds radial noise to an image.\"\"\"\n",
    "    h, w, _ = image.shape\n",
    "    center_y, center_x = h // 2, w // 2\n",
    "    y, x = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((x - center_x)**2 + (y - center_y)**2)\n",
    "    max_dist = np.sqrt(center_x**2 + center_y**2)\n",
    "    normalized_dist = dist_from_center / max_dist\n",
    "    noise = np.random.normal(loc=0.0, scale=1.0, size=image.shape)\n",
    "    radial_noise = noise * normalized_dist[:, :, np.newaxis] * noise_factor\n",
    "    noisy_image = image + radial_noise\n",
    "    return np.clip(noisy_image, 0.0, 1.0)\n",
    "\n",
    "def add_mask(image, mask_size=16, num_masks=1):\n",
    "    \"\"\"Adds random masks to an image.\"\"\"\n",
    "    masked_image = image.copy()\n",
    "    h, w, _ = image.shape\n",
    "    for _ in range(num_masks):\n",
    "        y = np.random.randint(0, h - mask_size)\n",
    "        x = np.random.randint(0, w - mask_size)\n",
    "        masked_image[y:y+mask_size, x:x+mask_size, :] = 0\n",
    "    return masked_image\n",
    "\n",
    "def add_random_noise_mask(image):\n",
    "    altered_image = add_random_noise(image)\n",
    "    altered_image = add_mask(altered_image)\n",
    "    return altered_image\n",
    "\n",
    "datagen_rand_noise = ImageDataGenerator(\n",
    "    preprocessing_function=add_random_noise  # Noise injection\n",
    ")\n",
    "\n",
    "# Radial noise\n",
    "datagen_radial_noise = ImageDataGenerator(\n",
    "    preprocessing_function=add_radial_noise  # Radial noise injection\n",
    ")\n",
    "\n",
    "# Flip\n",
    "datagen_flip = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "# Zoom\n",
    "datagen_zoom = ImageDataGenerator(\n",
    "    zoom_range=0.5 # Zoom in on the image\n",
    ")\n",
    "\n",
    "# Mask\n",
    "datagen_mask = ImageDataGenerator(\n",
    "    preprocessing_function = cutout  # Zoom in on the image\n",
    ")\n",
    "\n",
    "# Random noise and zoom\n",
    "datagen_rand_noise_zoom = ImageDataGenerator(\n",
    "    preprocessing_function=add_random_noise,  # Noise injection\n",
    "    zoom_range=0.1 # Zoom in on the image\n",
    ")\n",
    "\n",
    "# Random noise and mask\n",
    "datagen_rand_noise_mask = ImageDataGenerator(\n",
    "    preprocessing_function=add_random_noise_mask,  # Noise injection\n",
    ")\n",
    "\n",
    "# No noise\n",
    "datagen_no_noise = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Noise + Mask')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a sample image\n",
    "sample_image = x_train[0]\n",
    "img_arr = img_to_array(sample_image) \n",
    "img_arr = img_arr.reshape((1,) + img_arr.shape)\n",
    "# Apply different augmentations\n",
    "augmented_images = []\n",
    "# For the other augmentations, we can use the existing datagenerators\n",
    "\n",
    "# Apply each datagen separately to the same image\n",
    "augmented_images.append(img_arr)  # Original image\n",
    "\n",
    "# Random Noise\n",
    "augmented_images.append(datagen_rand_noise.flow(img_arr, batch_size=1))\n",
    "\n",
    "# Radial Noise\n",
    "augmented_images.append(datagen_radial_noise.flow(img_arr, batch_size=1))\n",
    "\n",
    "# Flip\n",
    "augmented_images.append(datagen_flip.flow(img_arr, batch_size=1))\n",
    "\n",
    "# Zoom\n",
    "augmented_images.append(datagen_zoom.flow(img_arr, batch_size=1))\n",
    "\n",
    "# Mask (Cutout)\n",
    "augmented_images.append(datagen_mask.flow(img_arr, batch_size=1))\n",
    "\n",
    "# Random Noise + Zoom\n",
    "augmented_images.append(datagen_rand_noise_zoom.flow(img_arr, batch_size=1))\n",
    "\n",
    "# No Augmentation\n",
    "augmented_images.append(datagen_rand_noise_mask.flow(img_arr, batch_size=1))\n",
    "\n",
    "f, xyarr = plt.subplots(2, 4, figsize=(10, 5))\n",
    "for ax in xyarr.flat:\n",
    "    ax.axis('off')  # This removes all axes, including scale bars\n",
    "plt.rcParams.update({'font.size': 12})  # Increase font size\n",
    "xyarr[0,0].imshow(augmented_images[0][0].squeeze(), cmap='gray')\n",
    "xyarr[0,0].set_title('Original')\n",
    "xyarr[0,1].imshow(augmented_images[1][0].squeeze(), cmap='gray')\n",
    "xyarr[0,1].set_title('Random Noise')\n",
    "xyarr[0,2].imshow(augmented_images[2][0].squeeze(), cmap='gray')\n",
    "xyarr[0,2].set_title('Radial Noise')\n",
    "xyarr[0,3].imshow(augmented_images[3][0].squeeze(), cmap='gray')\n",
    "xyarr[0,3].set_title('Flip')    \n",
    "xyarr[1,0].imshow(augmented_images[4][0].squeeze(), cmap='gray')\n",
    "xyarr[1,0].set_title('Zoom')\n",
    "xyarr[1,1].imshow(augmented_images[5][0].squeeze(), cmap='gray')\n",
    "xyarr[1,1].set_title('Cutout')\n",
    "xyarr[1,2].imshow(augmented_images[6][0].squeeze(), cmap='gray')\n",
    "xyarr[1,2].set_title('Noise + Zoom')\n",
    "xyarr[1,3].imshow(augmented_images[7][0].squeeze(), cmap='gray')\n",
    "xyarr[1,3].set_title('Noise + Mask')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_layers': 3, 'filters': [32, 64, 64], 'kernel_sizes': [[3, 3], [3, 3], [3, 3]], 'activations': ['relu', 'relu', 'relu'], 'dense_units': 64, 'dense_activation': 'relu', 'batch_normalization': True, 'pooling': 'avg'}\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2032 - accuracy: 0.9444 - val_loss: 0.0979 - val_accuracy: 0.9705\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0710 - accuracy: 0.9791 - val_loss: 0.0918 - val_accuracy: 0.9717\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0485 - accuracy: 0.9853 - val_loss: 0.0865 - val_accuracy: 0.9708\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0383 - accuracy: 0.9884 - val_loss: 0.0981 - val_accuracy: 0.9743\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 0.0525 - val_accuracy: 0.9838\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.0475 - val_accuracy: 0.9862\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0507 - val_accuracy: 0.9850\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.0472 - val_accuracy: 0.9852\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.0444 - val_accuracy: 0.9867\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0411 - val_accuracy: 0.9885\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0485 - val_accuracy: 0.9877\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.0511 - val_accuracy: 0.9872\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.0445 - val_accuracy: 0.9868\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1833 - accuracy: 0.9520 - val_loss: 0.0756 - val_accuracy: 0.9763\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0641 - accuracy: 0.9814 - val_loss: 0.0510 - val_accuracy: 0.9840\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0444 - accuracy: 0.9867 - val_loss: 0.0753 - val_accuracy: 0.9768\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0353 - accuracy: 0.9892 - val_loss: 0.0363 - val_accuracy: 0.9882\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.0498 - val_accuracy: 0.9847\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.0551 - val_accuracy: 0.9840\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.0379 - val_accuracy: 0.9885\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.4758 - accuracy: 0.8569 - val_loss: 0.3036 - val_accuracy: 0.9000\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2144 - accuracy: 0.9342 - val_loss: 0.2503 - val_accuracy: 0.9248\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1684 - accuracy: 0.9470 - val_loss: 0.2026 - val_accuracy: 0.9355\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1393 - accuracy: 0.9568 - val_loss: 0.1341 - val_accuracy: 0.9608\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1222 - accuracy: 0.9629 - val_loss: 0.1648 - val_accuracy: 0.9475\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1066 - accuracy: 0.9674 - val_loss: 0.1680 - val_accuracy: 0.9498\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0990 - accuracy: 0.9691 - val_loss: 0.0990 - val_accuracy: 0.9698\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0921 - accuracy: 0.9714 - val_loss: 0.1025 - val_accuracy: 0.9683\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0846 - accuracy: 0.9738 - val_loss: 0.1349 - val_accuracy: 0.9568\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0805 - accuracy: 0.9751 - val_loss: 0.1023 - val_accuracy: 0.9693\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 14s 7ms/step - loss: 0.3872 - accuracy: 0.8849 - val_loss: 0.2624 - val_accuracy: 0.9168\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.1758 - accuracy: 0.9457 - val_loss: 0.0840 - val_accuracy: 0.9747\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.1351 - accuracy: 0.9580 - val_loss: 0.1059 - val_accuracy: 0.9705\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.1157 - accuracy: 0.9636 - val_loss: 0.0751 - val_accuracy: 0.9758\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1014 - accuracy: 0.9688 - val_loss: 0.0811 - val_accuracy: 0.9757\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0906 - accuracy: 0.9719 - val_loss: 0.0554 - val_accuracy: 0.9830\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0846 - accuracy: 0.9737 - val_loss: 0.0519 - val_accuracy: 0.9848\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0769 - accuracy: 0.9768 - val_loss: 0.0555 - val_accuracy: 0.9817\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0722 - accuracy: 0.9776 - val_loss: 0.0927 - val_accuracy: 0.9713\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0685 - accuracy: 0.9781 - val_loss: 0.0403 - val_accuracy: 0.9863\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0654 - accuracy: 0.9800 - val_loss: 0.0495 - val_accuracy: 0.9853\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0618 - accuracy: 0.9804 - val_loss: 0.0312 - val_accuracy: 0.9903\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0568 - accuracy: 0.9820 - val_loss: 0.0455 - val_accuracy: 0.9857\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0557 - accuracy: 0.9824 - val_loss: 0.0470 - val_accuracy: 0.9872\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0501 - accuracy: 0.9841 - val_loss: 0.0431 - val_accuracy: 0.9863\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 10s 5ms/step - loss: 0.4048 - accuracy: 0.8751 - val_loss: 0.1133 - val_accuracy: 0.9643\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2047 - accuracy: 0.9341 - val_loss: 0.0577 - val_accuracy: 0.9818\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1676 - accuracy: 0.9458 - val_loss: 0.0736 - val_accuracy: 0.9777\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1455 - accuracy: 0.9523 - val_loss: 0.0569 - val_accuracy: 0.9822\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1290 - accuracy: 0.9578 - val_loss: 0.0488 - val_accuracy: 0.9847\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1233 - accuracy: 0.9599 - val_loss: 0.1163 - val_accuracy: 0.9640\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1133 - accuracy: 0.9632 - val_loss: 0.0374 - val_accuracy: 0.9893\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1054 - accuracy: 0.9657 - val_loss: 0.0331 - val_accuracy: 0.9893\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0980 - accuracy: 0.9681 - val_loss: 0.0295 - val_accuracy: 0.9908\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0942 - accuracy: 0.9692 - val_loss: 0.0334 - val_accuracy: 0.9912\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0897 - accuracy: 0.9697 - val_loss: 0.0386 - val_accuracy: 0.9897\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0857 - accuracy: 0.9719 - val_loss: 0.0238 - val_accuracy: 0.9942\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0823 - accuracy: 0.9733 - val_loss: 0.0324 - val_accuracy: 0.9903\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0829 - accuracy: 0.9730 - val_loss: 0.0278 - val_accuracy: 0.9922\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0780 - accuracy: 0.9740 - val_loss: 0.0263 - val_accuracy: 0.9935\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.2152 - accuracy: 0.9414 - val_loss: 0.1105 - val_accuracy: 0.9652\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0828 - accuracy: 0.9747 - val_loss: 0.0591 - val_accuracy: 0.9830\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0572 - accuracy: 0.9827 - val_loss: 0.0605 - val_accuracy: 0.9830\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0483 - accuracy: 0.9857 - val_loss: 0.0557 - val_accuracy: 0.9845\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0379 - accuracy: 0.9881 - val_loss: 0.0477 - val_accuracy: 0.9850\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0318 - accuracy: 0.9898 - val_loss: 0.0597 - val_accuracy: 0.9820\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 0.0447 - val_accuracy: 0.9872\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.0392 - val_accuracy: 0.9898\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.0378 - val_accuracy: 0.9897\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0415 - val_accuracy: 0.9885\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.0371 - val_accuracy: 0.9910\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0520 - val_accuracy: 0.9867\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 0.0434 - val_accuracy: 0.9888\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.0342 - val_accuracy: 0.9897\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0375 - val_accuracy: 0.9897\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.5823 - accuracy: 0.8147 - val_loss: 0.2716 - val_accuracy: 0.9188\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.3495 - accuracy: 0.8859 - val_loss: 0.6366 - val_accuracy: 0.8153\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2894 - accuracy: 0.9044 - val_loss: 0.3201 - val_accuracy: 0.8967\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2592 - accuracy: 0.9145 - val_loss: 0.5202 - val_accuracy: 0.8427\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1908 - accuracy: 0.9495 - val_loss: 0.0904 - val_accuracy: 0.9715\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0641 - accuracy: 0.9811 - val_loss: 0.0690 - val_accuracy: 0.9777\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0467 - accuracy: 0.9864 - val_loss: 0.0520 - val_accuracy: 0.9835\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0493 - val_accuracy: 0.9867\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 0.0435 - val_accuracy: 0.9852\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 0.0399 - val_accuracy: 0.9878\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0473 - val_accuracy: 0.9848\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0425 - val_accuracy: 0.9878\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0310 - val_accuracy: 0.9902\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0392 - val_accuracy: 0.9873\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0412 - val_accuracy: 0.9887\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0389 - val_accuracy: 0.9897\n"
     ]
    }
   ],
   "source": [
    "# Load the hyperparameters\n",
    "hyperparameters = json.load(open('hyperparameters.json'))\n",
    "print(hyperparameters)\n",
    "# Create the models with different noise injection\n",
    "best_model_rand_noise = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "best_model_radial_noise = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "best_model_flip = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "best_model_zoom = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "best_model_mask = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "best_model_rand_noise_zoom = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "best_model_rand_noise_mask = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "best_model_no_noise = create_cnn_model(input_shape, num_classes, hyperparameters)\n",
    "\n",
    "\n",
    "\n",
    "datagen_val = ImageDataGenerator()\n",
    "# Wrap the datagen with our custom generator\n",
    "train_generator_rand_noise = datagen_rand_noise.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_radial_noise = datagen_radial_noise.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_flip = datagen_flip.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_zoom = datagen_zoom.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_mask = datagen_mask.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_rand_noise_zoom = datagen_rand_noise_zoom.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_rand_noise_mask = datagen_rand_noise_mask.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_no_noise = datagen_no_noise.flow(x_train, y_train, batch_size=32)\n",
    "val_generator = datagen_val.flow(x_val, y_val, batch_size=32)\n",
    "# Train the model with custom augmentation\n",
    "augmentation_loss_df = pd.DataFrame()\n",
    "augmentation_accuracy_df = pd.DataFrame()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "# Random noise\n",
    "history_rand_noise = best_model_rand_noise.fit(train_generator_rand_noise,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,  \n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_rand_noise.history['val_loss'][-1]\n",
    "last_val_accuracy = history_rand_noise.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_rand_noise.history['val_loss']), 16):\n",
    "    history_rand_noise.history['val_loss'].append(last_val_loss)\n",
    "    history_rand_noise.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"rand_noise\"] = history_rand_noise.history['val_loss']\n",
    "augmentation_accuracy_df[f\"rand_noise\"] = history_rand_noise.history['val_accuracy']\n",
    "\n",
    "# Radial noise\n",
    "history_radial_noise = best_model_radial_noise.fit(train_generator_radial_noise,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,  \n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_radial_noise.history['val_loss'][-1]\n",
    "last_val_accuracy = history_radial_noise.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_radial_noise.history['val_loss']), 16):\n",
    "    history_radial_noise.history['val_loss'].append(last_val_loss)\n",
    "    history_radial_noise.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"radial_noise\"] = history_radial_noise.history['val_loss']\n",
    "augmentation_accuracy_df[f\"radial_noise\"] = history_radial_noise.history['val_accuracy']\n",
    "\n",
    "\n",
    "# Flip\n",
    "history_flip = best_model_flip.fit(train_generator_flip,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_flip.history['val_loss'][-1]\n",
    "last_val_accuracy = history_flip.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_flip.history['val_loss']), 16):\n",
    "    history_flip.history['val_loss'].append(last_val_loss)\n",
    "    history_flip.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"flip\"] = history_flip.history['val_loss']\n",
    "augmentation_accuracy_df[f\"flip\"] = history_flip.history['val_accuracy']\n",
    "\n",
    "# Zoom\n",
    "history_zoom = best_model_zoom.fit(train_generator_zoom,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_zoom.history['val_loss'][-1]\n",
    "last_val_accuracy = history_zoom.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_zoom.history['val_loss']), 16):\n",
    "    history_zoom.history['val_loss'].append(last_val_loss)\n",
    "    history_zoom.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"zoom\"] = history_zoom.history['val_loss']\n",
    "augmentation_accuracy_df[f\"zoom\"] = history_zoom.history['val_accuracy']\n",
    "\n",
    "# Mask\n",
    "history_mask = best_model_mask.fit(train_generator_mask,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_mask.history['val_loss'][-1]\n",
    "last_val_accuracy = history_mask.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_mask.history['val_loss']), 16):\n",
    "    history_mask.history['val_loss'].append(last_val_loss)\n",
    "    history_mask.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"mask\"] = history_mask.history['val_loss']\n",
    "augmentation_accuracy_df[f\"mask\"] = history_mask.history['val_accuracy']\n",
    "\n",
    "# Rand noise and zoom\n",
    "history_rand_noise_zoom = best_model_rand_noise_zoom.fit(train_generator_rand_noise_zoom,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_rand_noise_zoom.history['val_loss'][-1]\n",
    "last_val_accuracy = history_rand_noise_zoom.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_rand_noise_zoom.history['val_loss']), 16):\n",
    "    history_rand_noise_zoom.history['val_loss'].append(last_val_loss)\n",
    "    history_rand_noise_zoom.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"rand_noise_zoom\"] = history_rand_noise_zoom.history['val_loss']\n",
    "augmentation_accuracy_df[f\"rand_noise_zoom\"] = history_rand_noise_zoom.history['val_accuracy']\n",
    "\n",
    "# Random noise and mask\n",
    "history_rand_noise_mask = best_model_rand_noise_mask.fit(train_generator_rand_noise_mask,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_rand_noise_mask.history['val_loss'][-1]\n",
    "last_val_accuracy = history_rand_noise_mask.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_rand_noise_mask.history['val_loss']), 16):\n",
    "    history_rand_noise_mask.history['val_loss'].append(last_val_loss)\n",
    "    history_rand_noise_mask.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"rand_noise_mask\"] = history_rand_noise_mask.history['val_loss']\n",
    "augmentation_accuracy_df[f\"rand_noise_mask\"] = history_rand_noise_mask.history['val_accuracy']\n",
    "\n",
    "# No noise\n",
    "history_no_noise = best_model_no_noise.fit(train_generator_no_noise,\n",
    "                        epochs=15,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_no_noise.history['val_loss'][-1]\n",
    "last_val_accuracy = history_no_noise.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_no_noise.history['val_loss']), 16):\n",
    "    history_no_noise.history['val_loss'].append(last_val_loss)\n",
    "    history_no_noise.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"no_noise\"] = history_no_noise.history['val_loss']\n",
    "augmentation_accuracy_df[f\"no_noise\"] = history_no_noise.history['val_accuracy']\n",
    "\n",
    "# Save the dataframes to CSV files\n",
    "augmentation_loss_df.to_csv('augmentation_loss.csv', index=False)\n",
    "augmentation_accuracy_df.to_csv('augmentation_accuracy.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand noise test accuracy: 0.9647\n",
      "Rand noise test loss: 0.1557\n",
      "Radial noise test accuracy: 0.9623\n",
      "Radial noise test loss: 0.1362\n",
      "Flip test accuracy: 0.9259\n",
      "Flip test loss: 0.2598\n",
      "Zoom test accuracy: 0.9647\n",
      "Zoom test loss: 0.1349\n",
      "Mask test accuracy: 0.9693\n",
      "Mask test loss: 0.1327\n",
      "Rand noise and zoom test accuracy: 0.9697\n",
      "Rand noise and zoom test loss: 0.1519\n",
      "Rand noise and mask test accuracy: 0.8253\n",
      "Rand noise and mask test loss: 0.5927\n",
      "No noise test accuracy: 0.9670\n",
      "No noise test loss: 0.1402\n"
     ]
    }
   ],
   "source": [
    "rand_noise_loss, rand_noise_accuracy = best_model_rand_noise.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Rand noise test accuracy: {rand_noise_accuracy:.4f}\")\n",
    "print(f\"Rand noise test loss: {rand_noise_loss:.4f}\")\n",
    "radial_noise_loss, radial_noise_accuracy = best_model_radial_noise.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Radial noise test accuracy: {radial_noise_accuracy:.4f}\")\n",
    "print(f\"Radial noise test loss: {radial_noise_loss:.4f}\")\n",
    "flip_loss, flip_accuracy = best_model_flip.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Flip test accuracy: {flip_accuracy:.4f}\")\n",
    "print(f\"Flip test loss: {flip_loss:.4f}\")\n",
    "zoom_loss, zoom_accuracy = best_model_zoom.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Zoom test accuracy: {zoom_accuracy:.4f}\")\n",
    "print(f\"Zoom test loss: {zoom_loss:.4f}\")\n",
    "mask_loss, mask_accuracy = best_model_mask.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Mask test accuracy: {mask_accuracy:.4f}\")\n",
    "print(f\"Mask test loss: {mask_loss:.4f}\")\n",
    "rand_noise_zoom_loss, rand_noise_zoom_accuracy = best_model_rand_noise_zoom.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Rand noise and zoom test accuracy: {rand_noise_zoom_accuracy:.4f}\")\n",
    "print(f\"Rand noise and zoom test loss: {rand_noise_zoom_loss:.4f}\")\n",
    "rand_noise_mask_loss, rand_noise_mask_accuracy = best_model_rand_noise_mask.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Rand noise and mask test accuracy: {rand_noise_mask_accuracy:.4f}\")\n",
    "print(f\"Rand noise and mask test loss: {rand_noise_mask_loss:.4f}\")\n",
    "no_noise_loss, no_noise_accuracy = best_model_no_noise.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"No noise test accuracy: {no_noise_accuracy:.4f}\")\n",
    "print(f\"No noise test loss: {no_noise_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "313/313 [==============================] - 1s 1ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# List of models and their names\n",
    "models = [\n",
    "    (best_model_rand_noise, \"Random Noise\"),\n",
    "    (best_model_radial_noise, \"Radial Noise\"),\n",
    "    (best_model_flip, \"Flip\"),\n",
    "    (best_model_zoom, \"Zoom\"),\n",
    "    (best_model_mask, \"Mask\"),\n",
    "    (best_model_rand_noise_zoom, \"Random Noise + Zoom\"),\n",
    "    (best_model_rand_noise_mask, \"Random Noise + Mask\"),\n",
    "    (best_model_no_noise, \"No Noise\")\n",
    "]\n",
    "\n",
    "# Create and save confusion matrices for each model\n",
    "for model, name in models:\n",
    "    # Predictions on the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Confusion matrix\n",
    "    confusion = confusion_matrix(y_test, y_pred_class)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    disp.plot(ax=ax)\n",
    "    plt.title(f'Confusion Matrix for {name}')\n",
    "    \n",
    "    # Save the figure\n",
    "    now = datetime.datetime.now()\n",
    "    plt.savefig(f'confusion_matrix_{name.replace(\" \", \"_\").lower()}_{now.strftime(\"%Y-%m-%d\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
