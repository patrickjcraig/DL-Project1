{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from models.MLP import create_mlp\n",
    "import itertools\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(f):\n",
    "    # Move up one directory when loading the data\n",
    "    file_path = os.path.join('..', f)\n",
    "    return np.load(file_path)['arr_0']\n",
    "\n",
    "# Load the data\n",
    "X_train = load('kmnist-train-imgs.npz').reshape(-1, 28*28) / 255.0\n",
    "x_test = load('kmnist-test-imgs.npz').reshape(-1, 28*28) / 255.0\n",
    "y_train = load('kmnist-train-labels.npz')\n",
    "y_test = load('kmnist-test-labels.npz')\n",
    "\n",
    "# Reshape the data for input layer\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1) 10\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape and number of classes\n",
    "input_shape = X_train.shape[1:]  # 784 for KMNIST\n",
    "num_classes = y_train.max() + 1\n",
    "\n",
    "print(input_shape, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Model ID 1: Architecture: {0: 2000}, Dropout: 0.0, Optimizer: adam, Learning Rate: 0.001, Activation: relu\n",
      "Epoch 1/20\n",
      "844/844 [==============================] - 8s 9ms/step - loss: 0.3075 - accuracy: 0.9061 - val_loss: 0.1796 - val_accuracy: 0.9463\n",
      "Epoch 2/20\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 0.1192 - accuracy: 0.9652 - val_loss: 0.1458 - val_accuracy: 0.9528\n",
      "Epoch 3/20\n",
      "758/844 [=========================>....] - ETA: 0s - loss: 0.0619 - accuracy: 0.9815"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Confuison matrix for each model\u001b[39;00m\n\u001b[0;32m     47\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_val)\n",
      "File \u001b[1;32mc:\\Users\\patri\\anaconda3\\envs\\eel4930\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\patri\\anaconda3\\envs\\eel4930\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\patri\\anaconda3\\envs\\eel4930\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\patri\\anaconda3\\envs\\eel4930\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\patri\\anaconda3\\envs\\eel4930\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\patri\\anaconda3\\envs\\eel4930\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\patri\\anaconda3\\envs\\eel4930\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\patri\\anaconda3\\envs\\eel4930\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\patri\\anaconda3\\envs\\eel4930\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a range of hyperparameters to test\n",
    "architectures = [\n",
    "    {0: 2000},\n",
    "    {0: 1000, 1: 1000},\n",
    "    {0: 500, 1: 1000, 2: 500},\n",
    "]\n",
    "dropout_rates = [0.0, 0.5]\n",
    "optimizers = ['adam']\n",
    "learning_rates = [0.001, 0.01]\n",
    "activations = ['relu', 'tanh']\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "best_model = None\n",
    "\n",
    "# Generate all combinations of hyperparameters\n",
    "hyperparameter_configs = list(itertools.product(architectures, dropout_rates, optimizers, learning_rates, activations))\n",
    "\n",
    "# Create figures for learning curves with larger size\n",
    "fig_train, ax_train = plt.subplots(figsize=(12, 8))\n",
    "fig_val, ax_val = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Test different combinations\n",
    "model_id = 0\n",
    "epochs=20\n",
    "for arch, dropout_rate, optimizer, lr, activation in hyperparameter_configs:\n",
    "   \n",
    "    model_id += 1\n",
    "    print(f\"Testing Model ID {model_id}: Architecture: {arch}, Dropout: {dropout_rate}, Optimizer: {optimizer}, Learning Rate: {lr}, Activation: {activation}\")\n",
    "    # Create the MLP model\n",
    "    model = create_mlp(input_shape, num_classes, arch, activation=activation, learning_rate=lr, optimizer=optimizer, dropout_rate=dropout_rate)\n",
    "    \n",
    "    # Define callback for early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=64,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Confuison matrix for each model\n",
    "    y_pred = model.predict(x_val)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.arange(10))\n",
    "    plt.title(f'Model_{model_id} Confusion Matrix')\n",
    "    disp.plot()\n",
    "    plt.savefig(f'confusion_matrix/model_{model_id}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    # Save the best model based on validation accuracy\n",
    "    if not best_model or history.history['val_accuracy'][-1] > best_model['val_accuracy']:\n",
    "        best_model = {\n",
    "            'model_id': model_id,\n",
    "            'architecture': arch,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'optimizer': optimizer,\n",
    "            'learning_rate': lr,\n",
    "            'activation': activation,\n",
    "            'val_accuracy': history.history['val_accuracy'][-1],\n",
    "            'epochs_trained': len(history.history['val_accuracy']),\n",
    "            'val_loss': history.history['val_loss'][-1]\n",
    "        }\n",
    "        model.save('best_model.h5')\n",
    "    \n",
    "    # Create list for validation learning curve\n",
    "    val_learning_curve = []\n",
    "    val_learning_curve.append(history.history['val_accuracy'])\n",
    "\n",
    "    # Save the results\n",
    "    results.append({\n",
    "        'model_id': model_id,\n",
    "        'architecture': arch,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'optimizer': optimizer,\n",
    "        'learning_rate': lr,\n",
    "        'activation': activation,\n",
    "        'val_accuracy': max(history.history['val_accuracy']),\n",
    "        'val_loss': min(history.history['val_loss']),\n",
    "        'epochs_trained': len(history.history['val_loss']),\n",
    "        'val_learning curve' : val_learning_curve,\n",
    "        'test_accuracy': accuracy_score(y_test, y_pred),\n",
    "    })\n",
    "\n",
    "    # Plot learning curves for each model iteration\n",
    "    ax_train.plot(history.history['accuracy'], label=f'Model_{model_id}_train')\n",
    "    ax_val.plot(history.history['val_accuracy'], label=f'Model_{model_id}_val')\n",
    "    \n",
    "    \n",
    "\n",
    "# Finalize and show the plots\n",
    "ax_train.set_title('Training Accuracy Curve')\n",
    "ax_train.set_xlabel('Epoch')\n",
    "ax_train.set_ylabel('Accuracy')\n",
    "ax_train.legend()\n",
    "\n",
    "ax_val.set_title('Validation Accuracy Curve')\n",
    "ax_val.set_xlabel('Epoch')\n",
    "ax_val.set_ylabel('Accuracy')\n",
    "ax_val.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save results to json\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Find the best model\n",
    "best_model = min(results, key=lambda x: x['val_loss'])\n",
    "\n",
    "print(\"\\nBest Model Configuration:\")\n",
    "print(f\"Model ID: {best_model['model_id']}\")\n",
    "print(f\"Architecture: {best_model['architecture']}\")\n",
    "print(f\"Dropout Rate: {best_model['dropout_rate']}\")\n",
    "print(f\"Optimizer: {best_model['optimizer']}\")\n",
    "print(f\"Learning Rate: {best_model['learning_rate']}\")\n",
    "print(f\"Activation: {best_model['activation']}\")\n",
    "print(f\"Best Validation Accuracy: {best_model['val_accuracy']:.4f}\")\n",
    "print(f\"Best Validation Loss: {best_model['val_loss']:.4f}\")\n",
    "print(f\"Epochs Trained: {best_model['epochs_trained']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Json file\n",
    "with open('results.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Print test accuracy for each model\n",
    "for model in data:\n",
    "    print(f\"Model ID: {model['model_id']}, Test Accuracy: {model['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Test Accuracy: 0.9248\n",
      "Best Model Test Loss: 0.3207\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_12 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1000)              785000    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 10)                10010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Hyperparameters:\n",
      "Architecture: {\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_12\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 28, 28, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"input_13\"}}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten_12\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_28\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1000, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": 42}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_16\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.5, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_29\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1000, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": 42}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_17\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.5, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_30\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.10.0\", \"backend\": \"tensorflow\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the best model\n",
    "best_model = tf.keras.models.load_model('best_model.h5')\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nBest Model Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Best Model Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout(image, mask_size=16, num_cutouts=1):\n",
    "    \"\"\"Applies Cutout augmentation to an image.\"\"\"\n",
    "    h, w, _ = image.shape\n",
    "    image_copy = image.copy()\n",
    "\n",
    "    for _ in range(num_cutouts):\n",
    "        x = np.random.randint(0, w)\n",
    "        y = np.random.randint(0, h)\n",
    "\n",
    "        # Ensure the cutout does not go out of bounds\n",
    "        x1 = np.clip(x - mask_size // 2, 0, w)\n",
    "        x2 = np.clip(x + mask_size // 2, 0, w)\n",
    "        y1 = np.clip(y - mask_size // 2, 0, h)\n",
    "        y2 = np.clip(y + mask_size // 2, 0, h)\n",
    "\n",
    "        # Set the cutout region to the mean value of the image\n",
    "        mask_color = np.mean(image_copy)\n",
    "        image_copy[y1:y2, x1:x2, :] = mask_color\n",
    "\n",
    "    return image_copy\n",
    "\n",
    "# Random noise\n",
    "def add_random_noise(image, noise_factor=0.1):\n",
    "    \"\"\"Adds random noise to an image.\"\"\"\n",
    "    noisy_image = image + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=image.shape)\n",
    "    return np.clip(noisy_image, 0.0, 1.0)\n",
    "\n",
    "def add_radial_noise(image, noise_factor=0.1):\n",
    "    \"\"\"Adds radial noise to an image.\"\"\"\n",
    "    h, w, _ = image.shape\n",
    "    center_y, center_x = h // 2, w // 2\n",
    "    y, x = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((x - center_x)**2 + (y - center_y)**2)\n",
    "    max_dist = np.sqrt(center_x**2 + center_y**2)\n",
    "    normalized_dist = dist_from_center / max_dist\n",
    "    noise = np.random.normal(loc=0.0, scale=1.0, size=image.shape)\n",
    "    radial_noise = noise * normalized_dist[:, :, np.newaxis] * noise_factor\n",
    "    noisy_image = image + radial_noise\n",
    "    return np.clip(noisy_image, 0.0, 1.0)\n",
    "\n",
    "def add_mask(image, mask_size=16, num_masks=1):\n",
    "    \"\"\"Adds random masks to an image.\"\"\"\n",
    "    masked_image = image.copy()\n",
    "    h, w, _ = image.shape\n",
    "    for _ in range(num_masks):\n",
    "        y = np.random.randint(0, h - mask_size)\n",
    "        x = np.random.randint(0, w - mask_size)\n",
    "        masked_image[y:y+mask_size, x:x+mask_size, :] = 0\n",
    "    return masked_image\n",
    "\n",
    "def add_random_noise_mask(image):\n",
    "    altered_image = add_random_noise(image)\n",
    "    altered_image = add_mask(altered_image)\n",
    "    return altered_image\n",
    "\n",
    "datagen_rand_noise = ImageDataGenerator(\n",
    "    preprocessing_function=add_random_noise  # Noise injection\n",
    ")\n",
    "\n",
    "# Radial noise\n",
    "datagen_radial_noise = ImageDataGenerator(\n",
    "    preprocessing_function=add_radial_noise  # Radial noise injection\n",
    ")\n",
    "\n",
    "# Flip\n",
    "datagen_flip = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "# Zoom\n",
    "datagen_zoom = ImageDataGenerator(\n",
    "    zoom_range=0.5 # Zoom in on the image\n",
    ")\n",
    "\n",
    "# Mask\n",
    "datagen_mask = ImageDataGenerator(\n",
    "    preprocessing_function = cutout  # Zoom in on the image\n",
    ")\n",
    "\n",
    "# Random noise and zoom\n",
    "datagen_rand_noise_zoom = ImageDataGenerator(\n",
    "    preprocessing_function=add_random_noise,  # Noise injection\n",
    "    zoom_range=0.1 # Zoom in on the image\n",
    ")\n",
    "\n",
    "# Random noise and mask\n",
    "datagen_rand_noise_mask = ImageDataGenerator(\n",
    "    preprocessing_function=add_random_noise_mask,  # Noise injection\n",
    ")\n",
    "\n",
    "# No noise\n",
    "datagen_no_noise = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Noise + Mask')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAAGlCAYAAACSgevlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABw3UlEQVR4nO3deVhU5fs/8Jt9lV0FlEXEFVNRTAVNcckW18ytzCWz0jJN07I+5ZJa9nUvlzJTs7LUwspyy9xzyT0XVAQE3JAdEVmf3x/9IJH7xjk4B0Z9v66r68r3HM6cmTnPOfMwc96YKaUUAQAAAAAAGJl5ZW8AAAAAAAA8mDDZAAAAAAAAXWCyAQAAAAAAusBkAwAAAAAAdIHJBgAAAAAA6AKTDQAAAAAA0AUmGwAAAAAAoAtMNgAAAAAAQBeYbAAAAAAAgC4w2bhHZmZm1L59+3teT/v27cnMzOzeN0ij2NhYMjMzoyFDhlT4fcP9bcWKFWRmZkYrVqyo7E0xOXhuQDq2DhkyhMzMzCg2Nvae1l9Z5wxDGOsxAtwLbj/Ee57K8VBNNg4dOkRDhw6lgIAAsrOzIycnJ3rkkUdo/PjxdOnSpcrePHiImZmZlfjPwsKC3N3dKTw8nFatWkVKqcrexPve5MmTi5/fRYsWscsUTRL+97//VfDWgbFhTJVUNDmxsLCgf/75h12m6M3ZH3/8UcFbB2CYO8f1nf/hFzymybKyN6AiKKXonXfeoU8++YQsLS2pc+fO1KdPH8rNzaW//vqLZs2aRYsWLaKVK1fSs88+q2ndZ86cIXt7+3vexq+//ppu3rx5z+uB+9ukSZOIiCgvL4+ioqIoIiKCduzYQYcOHaL58+dX8tY9OCZPnkwDBw4kJycnXdbfq1cvatWqFXl5eemyfjCcqY2pjz76iN555x2qUaNGhd83EVFhYSGNHz+eNm3apNt9VPZjhAdf0bi+U9OmTcv8uRo1atCZM2fI2dlZh60CyUMx2Zg6dSp98skn5O/vTxs2bKCgoKASt//44480cOBA6t+/P23ZsoU6dOhg8Lrr169vlG309fU1ynrg/jZ58uQS/967dy899thj9Omnn9Kbb75J/v7+lbJdD5LAwECKioqimTNn0vTp03W5D2dnZ5zMTISpjSkvL69KnYQGBgbS5s2baevWrdS5c2dd7qOyHyM8+O4c14aysrIy2vs2MNwD/zWqmJgYmjZtGllZWdEvv/xSaqJBRNS7d2+aO3cuFRQU0IgRI6iwsJCISn7v+rfffqPHHnuMnJycSnxPVrpm48qVKzR06FCqVq0a2dnZUdOmTWnlypW0Y8cOMjMzKzVQuO/f3r7ssWPH6OmnnyYXFxeyt7enxx57jPbu3Vvqfi9fvkxTp06lsLAw8vT0JGtra/L29qYBAwbQqVOnyvEMQmUKCwujBg0akFKKDh06VOK2w4cP0+jRo6lJkybk5uZGtra2VKdOHRo7diylpKSUWtft+/P27dupffv2VKVKFXJycqKnnnpK3D+ioqKoT58+5OrqSg4ODhQaGkobNmwoc7sPHTpEzzzzDFWrVo1sbGzIz8+PRowYQZcvXy61bNFXN2JiYuizzz6joKAgsrOzI39/f5oxY0bx112+//57atGiBdnb21O1atVo1KhRdOvWLUOfymKjRo0ib29vmjt3LiUkJBj8c5cvX6aRI0eSv78/WVtbU9WqValXr170999/l1pWumbj6NGj1K9fP/Lz8yMbGxtyd3enxo0b0+jRoykvL6/Esvn5+bRo0SJq1aoVOTk5kb29PQUHB9Nnn31WfIwC7Yw5poiIMjMzaezYsVSzZk2ytbWl+vXr0+zZs8XXSLqeYcWKFdS7d+8SX/MNCwujr7/+2iiPu8iMGTPIzMyMxo8fr2k/Ks+YvvMxRkREUHh4OHl6epKNjQ15enpSmzZtaOHChaXWkZKSQhMnTqQGDRqQnZ0dOTs7U8eOHWnLli2aHzNAkbtdSxUdHU1z5syh+vXrk62tLdWsWZPefPNNysjIqJwNfkA88JON5cuXU35+PvXs2ZMeeeQRcbmXXnqJvLy86Ny5c7Rz584St61du5a6d+9Ozs7O9Oqrr971q1aJiYkUGhpKK1asoAYNGtCYMWMoODiYRo4cWa6P7Q8dOkShoaF069Yteumll6hr1660d+9e6tixI505c6bEsrt27aKPP/6YXFxcqHfv3jRmzBhq2bIlrVu3jh599FE6duyY5vuHylX0hsDSsuQHkUuXLqXvv/+e6tWrR0OHDqVXX32VqlevTnPnzqXQ0FDKzMxk17dhwwZ6/PHHycnJiV599VVq27Ytbdy4kdq3b0/Xr18vsez58+epVatWtG7dOmrdujWNHj2aatasST179qSffvqJXf/PP/9MoaGh9Ntvv1Hnzp1p7NixVLduXVqyZAmFhIRQdHQ0+3NvvfUWTZo0iVq0aEGvvPIKmZub03vvvUdTp06l2bNn04svvkh16tShESNGkJeXF3322Wf05ptvan06yd7enj788EPKzs6m9957z6CfiY6OppCQEFq8eDEFBgbSuHHjqEuXLvT7779TWFgY/fzzz3ddx7Fjx6h169b066+/UuvWrWns2LHUv39/8vLyosWLF1NOTk7xsnl5edS1a1d67bXXKD09nZ577jl6+eWXqbCwkEaNGkWDBg3S/LjhP8YaUzk5OdSxY0eaO3cueXh40OjRo6ldu3Y0bdo0GjNmjKZtGjFiBMXGxtJjjz1GY8aMoX79+lFMTAwNHjyY3n333Xt6vLcLDg6mgQMH0vHjx2nlypUG/Ux5x/TtFi9eTM888wxFRkZS9+7dady4cdS1a1fKzc0tNSm/ePEiNW/enD7++GOqVq0ajRgxgvr160dnzpyhJ554gr744ovyPHSAu3rzzTfpww8/pHbt2tHo0aPJw8OD5s2bRx06dCjXL7fg/1MPuPDwcEVE6osvvrjrsgMGDFBEpD788EOllFLLly9XRKTMzMzUxo0b2Z8hItWuXbsS2YsvvqiISE2YMKFEfuzYMWVtba2ISE2aNKnEbe3atVN3vhzbt29XRKSISK1YsaLEbUuWLFFEpF599dUS+bVr11RGRkap7Tx8+LCyt7dXXbp0KZHHxMQoIlKDBw9mHx9UjKLX+U67d+9W5ubmytraWl26dKnEbbGxsSo/P7/UzxTtGx999FGJvGh/trCwUH/88UeJ29555x1FROrjjz8ukXfu3FkRkZo3b16JfP369cXbvHz58uI8MzNTubm5KQsLC7V3794SPzNjxgxFRKpTp04l8sGDBysiUn5+fiohIaE4T01NVe7u7sre3l65u7ur06dPF9+Wk5OjgoKClLW1tbp27Vqp54AzadIkRURq6dKlqqCgQDVu3FiZm5uro0ePlnqO3nvvPfZ5uPP5KXp9XF1dS4y7ovXc/ty8+eabiohUREREqW1LSUlRBQUFpbZ19OjRJV7j/Pz84uMLtx74T0WMqenTpysiUs8880yJ1y86Olq5urqyx9ai/T0mJqZEHhUVVep+b926pdq3b68sLS1VfHx8idu4c0ZZipY/f/68iouLU7a2tqpGjRoqKyur1LZt3bq1OLuXMX37YwwODhbH6/Xr10ttq5mZmVqzZk2JPDU1VTVp0kTZ2tqqK1euGPzY4cFRNK4nTZpU6r/bj7dK8fuh9J6naFl3d3cVGxtbnBcUFKhnnnlGEZGaOnWqjo/swfbATzYaNGigiEicLNxuwoQJiojUiBEjlFL/vWHo0aOH+DN3TjZycnKUnZ2dcnZ2Zt/0v/TSS5onG23atCm1ntzcXGVpaamaN29+18dVpGvXrsrGxkbl5uYWZ5hsmIY7D6Dvvvuu6tevn7K2tlZmZmal3uyXpbCwUDk5Oanw8PASedH+PHDgwFI/Ex0drYhI9e7duziLj49XRKRq1arFvgEr2mdvP8CvWrVKEZF6/vnnSy2fm5ur/Pz8FBGVOJgXHeSXLVtW6meGDh2qiEi9//77pW6bMmWKIiK1Y8cO/om4w+2TDaWU2rRpkyIi1bFjx+JluMlG0fPg5+en8vLySq33ueeeU0SkVq5cWWo9tz83Y8eOVUSkNm/eXOZ2FhQUKHd3d+Xl5cU+76mpqcrMzEw9++yzBj3uh1VFjKnAwEBlbm7OThSK9jdDJxuSdevWldq/lLq3yYZS//2CoeiXa7dv2+2TjXsZ07c/xmbNmil7e3uVkpJS5nYeO3ZMEZHq06cPe3vRLzo+++wzgx43PFiKxjX3352/+C3PZIObUFy4cEGZm5srf39/HR7Rw+GBv0Bc/f/vexvSR160zJ3LtmzZ0uD7O3v2LGVnZ1NISAhVqVKl1O1t2rShL7/80uD1ERGFhISUyqysrKh69eqUmppa6rbffvuNlixZQocOHaKkpCTKz88vcXtSUhIu3jNRU6ZMKfFvMzMz+uqrr9hO8Ly8PPr888/p+++/p9OnT1N6enqJ72BLdc7c/uTj40NEVGJ/Onr0KBH9u89aWFiU+pn27duX+sph0c+Eh4eXWt7KyoratWtHX3/9NR09epT8/PxK3N68efNSP+Pt7X3X27Rcd3G7Ll260OOPP05btmyh33//nZ566il2uaLH1LZt21JfuyEi6tSpE3333Xd05MiRMr/e1L9/f5o/fz717NmT+vTpQx07dqSwsDCqXbt2ieXOnTtHycnJVKdOHfrwww/ZddnZ2VFkZKShD/WhpteYyszMpKioKPLx8Sn1GhL9Oz7uvO+yxMXF0cyZM2nbtm0UFxdH2dnZJW43dj37xIkTadmyZfTJJ5/Q8OHDqXr16uxy9zKmb/f888/TuHHjKCgoiPr370+PPfYYhYWFUdWqVUsst2/fPiIiSktLYy8CLvqqJ/b/h1vReztja9euXaksICCAfHx8KDY2ltLS0sjFxUWX+36QPfCTDS8vL4qMjKT4+Pi7Llv0puXON+Kenp4G3196ejoRkXjglvKySK02lpaWVFBQUCJbsGABjR49mlxdXalz587k6+tL9vb2ZGZmRuvXr6fjx4+X+G44mJaiA2hWVhb99ddf9OKLL9Krr75KtWrVKnUQ7NevH0VERFBAQAD16NGj+KJLIqJ58+aJrzO3PxW9ib59f7rbvsyNi6KfkcZM0dgqWs7Q7SrrtjsvrNZi1qxZ1LRpU5owYQJ16dKFXeZeHtPtWrRoQbt376bp06fT2rVriy/8rV+/Pk2ePJn69etHRETJyclE9O/1MmW9Wb1x40aZ9wf/0mtMlWd8SKKjo+nRRx+l1NRUatu2LT3++OPk7OxMFhYWFBsbSytXrjT6cdvJyYkmTZpEr7/+Ok2ePJkWL17MLmes/X/s2LHk4eFBixYtovnz59PcuXPJzMyMwsPD6f/+7/+oWbNmRPTf/r9161baunWruD7s/6CHssbzxYsXKT09HZONcnjgJxtt2rSh7du30x9//EEvvfSSuFxBQQFt376diP5tK7mdlr/SWtTbf+3aNfZ2KTeG/Px8mjRpEnl6etKRI0dKTZqKfmMEps/BwYE6d+5MGzZsoObNm9PAgQPp7NmzxX/T5dChQxQREUEdO3akjRs3kpWVVfHPFhYW0ieffHLP21D0Bl/aZ69evSr+DHcb0b8tbbcvV9keeeQRGjx4MC1fvpy++uqrEs9jEWM+ptatW9OGDRsoJyeHDh8+TJs2baJPP/2UBgwYQFWrVqUOHToUr6dXr17iRfignbHHVHnGh2TOnDmUnJxMy5cvL/WJy+rVqw2+kFurV155hRYsWEBLly6lN954g13GmPv/oEGDaNCgQZSWlkZ//fUXRURE0FdffUWPP/44nTlzhqpWrVq8nvnz54vbBKCXa9euUb169UrlRfu/qZy77jcPfBvVkCFDyMLCgn766Sc6ffq0uNxXX31Fly9fpnr16rEfoxmqfv36ZGdnRydOnGDbgPbs2VPudd9NUlISpaWlUWhoaKmJxo0bN+jIkSO63Tfoo0mTJjR8+HBKSEiguXPnFudRUVFERNSjR49Sb5APHjxY6isY5REcHExE/+6zd36CRvRvNbP0M9xt+fn5xft/0W8xTcG0adPI3t6ePvjgA8rKyip1++3Pw51fSSSi4l9SaHlMNjY2FBoaSlOnTqUFCxaQUorWr19PRP8eQ1xcXGj//v339KkN8Iw1pqpUqUKBgYF06dIlunDhQqn74caApOi+e/fuXeq2O7+qaEyWlpY0c+ZMKigooAkTJrDL6DGmXVxc6KmnnqKlS5fSkCFDKDk5mXbv3k1ERK1atSIiKv43QEXixlt0dDTFx8eTv78/PtUopwd+shEQEEDvvvsu5eXlUbdu3dgJx/r162n06NFkYWFBixYtInPz8j8t1tbW1K9fP0pPT6dp06aVuO348eNG70y/XbVq1cje3p4OHTpU4iPmvLw8Gj16NCUlJel236Cf//3vf2Rra0uzZs0qvqai6A+R3fkGIDExkV577TWj3G/NmjWpc+fOxX//4nY///wze1Du2bMnubm50erVq2n//v0lbps3bx5FR0dTp06dTOqPWHp7e9O4cePo6tWrNG/evFK3Fz0PsbGxpW4/cOAAfffdd+Tq6kq9evUq8352797NftWk6Dfjtra2RPTvG8BRo0bRlStX6I033mAnjleuXCnzlydQNmONqaFDh1JhYSG9/fbbJa7tiImJoQULFhi8PUX3XTRxLbJ582bN1/hp1bNnT2rbti1t2LCB/dtNxhrTmzZtYifriYmJRPTf/h8SEkJt27aln376ib766it2Xf/880/xzwEY0/z58+nixYvF/y4sLCz+mzRDhw6txC27vz3wX6Mi+vcvTWZlZdGcOXOoSZMm1KVLFwoKCqK8vDz666+/6MCBA2RnZ0erV6/W9NfDJR9//DH9+eef9Mknn9CBAwcoNDSUrly5QmvWrKGnnnqK1q9ff08TGom5uTm98cYb9PHHH9MjjzxCPXr0oNzcXNq+fTulpKRQeHh4qZMZmL4aNWrQK6+8QvPnz6dPPvmEPvroI2rRogWFhYXRTz/9RKGhodSmTRu6du0abdy4kerVq1d88fS9WrhwIbVu3ZrGjBlDW7ZsoSZNmlBUVBRFRERQt27d6Ndffy2xvKOjI3311VfUp08fateuHfXp04d8fX3p8OHDtGXLFvL09KTPP//cKNtmTBMmTKAvvvii+DfMd1qyZAmFhYXR+PHjacuWLRQSEkLx8fG0du1aMjc3p+XLl7OFELebPXs2bdmyhdq3b08BAQHk6OhIp06doo0bN5KLiwu9/PLLxcu+//77dPz4cVqyZAn9+uuv1KFDB6pRowYlJibS+fPnae/evTR9+nRq2LChUZ+Hh4WxxtS4ceNo/fr19OOPP1KzZs2oS5culJ6eTj/88AM99thj9Msvvxi0PSNHjqTly5dT3759qXfv3lSjRg06efIkbdq0ifr27Us//PCDsZ+CEmbNmkWtWrVi939jjen+/fuTra0ttWnThvz9/UkpRbt376a///6bmjVrRp06dSpe9rvvvqMOHTrQsGHDaMGCBdSyZUtycXGhhIQEOnHiBJ08eZL27dtH1apVM+rzANCmTRtq2rQp9evXj5ydnWnz5s10/Phxat68ufjpHxigMquwKtqBAwfUoEGDlL+/v7K1tVUODg4qKChIjRs3rlSHuVJ8feWdiKlbU0qphIQENWjQIOXh4aFsbW1VkyZN1IoVK9TatWvZv1tQVvXtnTW5Rfz8/JSfn1+JLC8vT82ePVs1aNBA2draqurVq6uBAweq2NhYTTVwULFI+JsARa5evars7e2Vvb29unr1qlJKqeTkZDVixAjl5+enbGxsVEBAgJo4caLKyspi94277c/Svnz+/HnVu3dv5ezsrOzt7VWrVq3Uhg0bylzfwYMHVc+ePZWHh4eysrJSPj4+6tVXXy31dw2UKrsKtKg+dPv27aVuM2R8cusqqr69U9HfUiDm72wo9e+YfvXVV5Wvr6+ysrJS7u7uqkePHurgwYMGbdvmzZvVkCFDVIMGDZSTk5Oyt7dXdevWVaNGjSpRG1qksLBQff3116pDhw7K1dVVWVlZKW9vbxUWFqamT5+u4uLiDHrcD6uKGFNKKZWenq7efPNN5e3trWxsbFS9evXUrFmz1IULFzRV3+7du1eFh4crFxcX5ejoqMLCwlRERIR4HrjX6ts79e/fv/g5u736tsi9junFixernj17qlq1aik7Ozvl6uqqmjZtqmbOnMnWxGdkZKjp06erZs2aKQcHB2Vra6v8/f3VU089pT7//HN148YNgx87PDjuNq5vV57q2wsXLqhZs2apevXqKRsbG+Xt7a1Gjx6t0tPTjfgoHj5mSunUHwas9957j2bMmEGbNm0S228AAAAAoGIMGTKEVq5cSTExMcVfawTjeeCv2agsly9fLpX9888/tGDBAnJ3d7+ni9ABAAAAAO4HD8U1G5UhJCSEAgMDqVGjRuTg4EDnz5+n3377jQoLC2np0qXFF8MBAAAAADyoMNnQyauvvkq//PILrVmzhtLT08nZ2ZmeeOIJeuutt/CpBgAAAAA8FHDNBgAAAAAA6ALXbAAAAAAAgC4w2QAAAAAAAF1gsgEAAAAAALow+AJxMzMzPbfjgdWtWzc2Hz9+vPgz4eHhbF5QUKDpvrt3787mrVu3ZvPVq1ez+YkTJzTdb2UxhcuPpJaxnJycCt4S45L+IjlX8VweAwYMYPPFixeLP+Pi4sLm9vb2bF6rVi02l/7ytzROzp8/z+abN29m87y8PDZ3dnZmcw8PDza/cOECm9vZ2bF5dnY2m5vCOHFycmLzzMxMNvfz82PzixcvarpfKysrNpdeI62k86TW51zaB4KCgth82rRp4rratm3L5m5ubmwuHcOCg4PZXDrPfPDBB2x+7do1Npdofc2k8S/9tfG4uDg213q+1Yve77369OnD5hEREWyen5+v5+Zo9vzzz7P5t99+W8Fb8vAy5PiGTzYAAAAAAEAXmGwAAAAAAIAuMNkAAAAAAABdYLIBAAAAAAC6eGj+grixLtyTuLq6snnjxo3ZfOjQoeK6jHVh2rZt29hcuqDvjz/+YPP169ez+ZgxY9j85s2bd922B5W0P1WtWpXNr1+/zubSRcthYWFsfujQITaXLkyXLsSVSBddalW/fn0279KlC5uHhIRovg/pwlEbGxs2P3fuHJt37tyZzdetW8fm//d//8fmn3/+OZvfuHGDza9cucLm0kXV5ub874ykC8RNgXSRafPmzdn88OHDbG5pyZ/CpPGWlpbG5tI+I61f2n5jnU+SkpLYPDQ0lM1ff/11zfch7U+xsbFsnpGRwebSBcbShdfvvPMOm8+dO5fNHRwc2Fx6LbWefwoLCzUtf7+SjhOvvfaapvWsXbvWGJujmXRObNiwYQVvCZQHPtkAAAAAAABdYLIBAAAAAAC6wGQDAAAAAAB0gckGAAAAAADoApMNAAAAAADQhZkysD5DanO6X7i4uLB5eno6m2ttFRk+fDibnz9/ns137Nihaf3GZGtry+Z9+/Zl8yVLlrC51CwktZDozVhNMPfCWONEawtO3bp12fzSpUts7uHhoel+L168qGl7JIMGDWJzqQFn165d4rocHR3ZXGp5kkgtLdI46datG5u/+OKLbC41z0n7ivSaSaytrdlceo21rl8PWsdJ7dq12Vxq7pP2J0lgYCCbR0VFsbnUPpiamsrm0uOVxlv//v3ZXGqp2rhxI5tXBKklSGqSk7ZVGm/u7u5sLo1zqYFP4ubmxubJycma1qMXY51TpOPc8ePH2dzOzo7Nu3btyuaRkZHl2zADaR1DUsMcGJ8h773wyQYAAAAAAOgCkw0AAAAAANAFJhsAAAAAAKALTDYAAAAAAEAXmGwAAAAAAIAuHpo2KhsbGzaXWk5Onz5tlPVrbcYwRY8++iibHzlyhM21NhQZiym0UTk4OLC51IyhtTHD3t6ezW/evMnmUlNRbm6upvvt3Lkzm1+5coXNT548qWn95VGzZk02T0hIMMr6pZadzMxMNu/SpQubb9682Sjr1/raS0xhnBjrfGJhYcHmUkuV1MhTWFio6X4DAgLY3MvLi8337t3L5lLTUkZGBptLr11Zx1zpuZban7KzszWtRzr3SftrnTp12PzAgQNs7unpyebSfi89d9JrL22/1nGlF2ONFWk927ZtY/Pw8HA2l1q6GjduzOaXL182YOvgfoY2KgAAAAAAqDSYbAAAAAAAgC4w2QAAAAAAAF1gsgEAAAAAALrAZAMAAAAAAHTx0LRRSa08Y8eOZfOZM2eyuSk0uQDPFF4bvceJ1F4jNchIbWguLi5sLjWNLF26lM0//PBDNo+Li2NzqT1Iet6k1h8iosTERDZPS0sTf8YYnJyc2Fxqr6levTqb161bl823b9/O5jVq1GDzS5cusbnEFMaJo6Mjm2dlZWlaj7Qfa90HmjdvzubHjx9nc6ntasyYMWw+d+5cNpeehxs3brC5xNvbW7xNer2TkpLYXGrUk55TrY1gWknnbul+tS4vbafexxFD6X1OCQsLY/ONGzeyudSid+zYMTbv3r07m8fHx9994+C+gDYqAAAAAACoNJhsAAAAAACALjDZAAAAAAAAXWCyAQAAAAAAusBkAwAAAAAAdPHQtFFJOnfuzOYeHh5svnr1aj03B+6BKbTsSONEap2Rmo2kNpqMjIzybdgdpBYfqYkmODiYzf39/dl8//79bH7o0KG7bptepMecmZnJ5lJLjZubG5unpKRo2h5LS0s2z8/P17QerUx5nHh6erJ5Xl4em0vtaXqzsbFh8w4dOrC5n58fmy9ZsoTNpUalwsJCNpf2JSKiW7duibcZg9SSJr1m5ub87zivXr2q6X69vLzY/MqVK2wutShJ498UxglR5b33GjVqFJvPnz+fzaXtjIqKYvNu3bqxeWRkpAFbB6YEbVQAAAAAAFBpMNkAAAAAAABdYLIBAAAAAAC6wGQDAAAAAAB0gckGAAAAAADo4qFvo5Ie15EjR9h8/fr1bD5lyhRjbRKUkym0h0jNLDk5OWxurDYdV1dXNre1tWXzrKwsNtfadvX333+z+Xfffcfmc+fO1bT+skjtMr6+vmweGxvL5tJzUVmklp2bN2+yeXp6OptL7Vupqanl2i5j0no+sbCwYHNpv09KStK8TXqS9r0ffviBzd9++21N6y+rjUpqN5NeA+k4qnd7mrOzM5tLbVrSMVUrqVlM7xYvQ1XWey/p9f7mm2/YvF+/fprWHxMTw+bPPPMMmx87dkzT+o1J61jRqlevXmw+cuRINn/66afZPDc31yjboxXaqAAAAAAAoNJgsgEAAAAAALrAZAMAAAAAAHSByQYAAAAAAOgCkw0AAAAAANCFXGHxkHjiiSfYXGo+MDfn52d6txXA/UFqc7px4wabS81DUsNLQUGBpuUTExM1rUfy7LPPsnlUVBSbu7m5aVp/06ZN2bysBpLMzEw2P3XqFJvr3eqi9Rjg7e3N5lLL1pUrV4yyPaZMaiSSGrek3M7Ojs2lthZpPEivhbTvDRw4kM137tzJ5lKjkoODA5tLzWlS6xyRfOyxsrJic2M12kivQXZ2NptLr6XU8Hfp0iVN2yO1s0nPz8NOOqe88cYbbC7ts3Xq1GHzwMBANt+/fz+bDx06lM2lRrfCwkI2L49Ro0axebt27dj8yy+/ZHPpOCC1z0nnsspqnboX+GQDAAAAAAB0gckGAAAAAADoApMNAAAAAADQBSYbAAAAAACgC0w2AAAAAABAF2bKwLqk+7HZ5HbNmjVjc6k1oH379mwutQ1B5TOF5q9GjRqxudQqITWtSC1S1atXZ3OpyUUitao1aNCAzVesWMHm9evXZ3N/f382T05OZnOp3ScoKIjNiYguX77M5qmpqWxuYWHB5lITkaUlX9YnNf84OTmxeUpKiqb7zcvLY3NXV1c2l/YJ6Xm4evUqm1ckrecTaX+6efMmm0vjR2qXkpp3pOak0NBQNp89ezabt27dms2lfVJqirp16xabS01LRPJjk1qYtLZISbSON+m1kcaD9FzY29trul9p3Er7UEW7X957Sfvsn3/+yebS/iHtr2FhYWw+a9YsNn/33XfZXGsTIxHRggUL2Pz1119nc2nfjImJYXPpXCO9b5Va6SqLIe+98MkGAAAAAADoApMNAAAAAADQBSYbAAAAAACgC0w2AAAAAABAF5hsAAAAAACALvhL4O9jNjY2bP7555+z+apVq9gcrVNQHlIDkOTSpUualk9ISNC0vERqMHrrrbfYfP78+WwutVFJTS5SC5a1tTWbSy1eZalZsyabS8+do6Mjm0ttPdJjkF57qZlEK2n9UluNtP2mQGpPkppoYmNj2VxqtJEahqTjutQG4+zszObLli1j83nz5rG5RGrG0dqYU1YbndQuJe030jk0NzeXzaVt1dqiJDXsFBYWalqP1FAmuX79uqblgSe1hh04cIDNR4wYweb9+vVj88cff5zNX331VTaXznHDhg1jcyJ5X5Pa56R9XBpzDRs2ZPOXX36ZzU2tdepe4JMNAAAAAADQBSYbAAAAAACgC0w2AAAAAABAF5hsAAAAAACALjDZAAAAAAAAXTxwbVRDhgxhc6kpQWoVgbuTGlwkUmuJUsoYm2MSsrOz2dzf35/NpSYUPz8/NpfaKS5evHj3jbuN1H6Rk5PD5t9//z2bSw1JUhuQ1N4hNd2URWot+e233zStR2trk7Ga6tzd3dlcasdycHBg89OnT7O51BRmCtLS0jQtL7VOSccU6TmUXjupDW3w4MFsLo2TNWvWsLmxSMfcshqbpHOfdNyVxoP0HEnHPKlZTCI9BqlV6Nq1a2wubWd5jjFw7z788EM279KlC5u/8MILbC4d7yMiItj8xx9/ZPORI0eyORHR1q1b2Vxqz1u9ejWbDxgwQLwPTrdu3dhcen+qtaHNFOCTDQAAAAAA0AUmGwAAAAAAoAtMNgAAAAAAQBeYbAAAAAAAgC4w2QAAAAAAAF2YKQOrgKQWmcoitQNIzSyvvfYam0tNBnqzsrISb5MaVqQGAnNzfs4oLS81HbVv357NpVabNm3asPnVq1fZfOLEiWweFRXF5lqZQquV9NzGxcWxudSaI5GaYuzs7Nhc2gdu3brF5k8++SSbHzhwgM2lNipJUFAQm586dYrNa9SoIa5LGidSy5PU/CU1I/n6+rK59JyGh4ezudR+cu7cOTZ/5ZVX2FxqIpOeBxsbGzaXXvuKJJ1PpLYlqdlIWo90LJDGm729PZv/9ddfbP7ee++x+dq1a9lcOkZLzUnSayStR2vzU1m0tjl5enqyedeuXdnc29ubzTt06MDm0dHRbD5nzhw2P3nyJJt7eXmxeWJiIpsb8zm9F6b23stYfv31VzaX9oN69eqxeUJCAptL57Ky3vNduHCBzT///HM2HzRoEJtnZmayufT+oFatWmzeunVrNt+/fz+bVxZD3nvhkw0AAAAAANAFJhsAAAAAAKALTDYAAAAAAEAXmGwAAAAAAIAuMNkAAAAAAABd8NUf94HatWuzebVq1dj8hRdeYHPpqv4rV66Ub8MMNG/ePPE2qU1nyJAhbC61hEik9o3HHnuMzQcPHszmUqvD7Nmz2Tw2NvbuG3efk1qnpFYlqX3n4sWLmu43OzubzaWmGMlbb73F5tK+JzWESONKap2SfPrpp+Jt/v7+bN6sWTM2l14DqR1HaklbtGgRm0vtO4cOHWLzxYsXs7k0nrW2reXk5GhaviJZWFhoWl5rQ5JEanMLDAxkc+k806NHDzaXWtukY5/WxiOpCW3JkiXiz3h4eLC51KSTl5fH5tKxSnoNmjRpwuavv/46m0vnky+++ILNpedU2lekdjapzQ30tWfPHjZv27Ytm2sd6xs3bmTzjh07ij/z/fffs/n8+fPZXBqPvXv3ZnNpn5Va7GrWrMnm9yN8sgEAAAAAALrAZAMAAAAAAHSByQYAAAAAAOgCkw0AAAAAANAFJhsAAAAAAKCL+7aN6uTJk2weEhLC5q1bt2bzNWvWsPm0adPYfPPmzQZs3d2dOHFCvE1q4Nm3bx+bf/bZZ2zu6+vL5suXL2fzOnXqsPmUKVPYfPr06WwuNTQ8DKTGE6lJ49KlS2wuNSodOXKEzatUqcLmUttNy5Yt2TwsLIzNN2zYwOZSU5mkbt26bC41P+3cuVNcl9RaIu2X3333HZtnZGSwudQIJj3XH374IZvPnTuXzV1cXNjc2dmZzaV2KSsrKza/fv06m5sCqQHIz8+PzaXXwtyc/32Zvb09m0ttVFL7YHBwMJs3b96czX/44Qc2/9///sfmf/zxB5tLzWNmZmZsLh0XiIgWLlzI5i+//DKbL1iwgM2l9reVK1eyuXT+eeedd9h85syZbK6VND7T0tKMsn4wjsuXL7O51IZmrHa9v//+W7wtNTWVzaVWKGmfksaQ9B5u5MiRbC69z70f4ZMNAAAAAADQBSYbAAAAAACgC0w2AAAAAABAF5hsAAAAAACALjDZAAAAAAAAXZgpqfbizgWFFoz73QsvvMDmc+bMYfPAwEA2T09P13S/1tbW4m2HDh1i80ceeYTNU1JS2DwrK4vNpUaEL7/8ks2lRgSpwaWyGLgr66pGjRpsLjVpSC1VmZmZRtsmYxg2bBibS81pVatWZXOpJUgaD1J7EBHR77//zuahoaHiz2ixf/9+NpeahaRGreTkZDaXmsJu3bplwNb9p3r16myemJjI5qbQFletWjU2l7ZNeg4llpZ80aLUgiXtl9Ix1MLCgs0HDBjA5osWLWLzgIAANk9KSmJzSVnnk6NHj7J5w4YN2Vxq5MnOzmbzHTt2sLnUghUfH68pl0ivgfQau7m5sbmdnR2bJyQkaNoevZjaey+pcbFBgwZsLjWBPvfcc2yudxPoK6+8It4mnc/Gjx/P5lITqPQ+QGsT6NKlS9nc1JpADXnvhU82AAAAAABAF5hsAAAAAACALjDZAAAAAAAAXWCyAQAAAAAAusBkAwAAAAAAdIHJBgAAAAAA6ILvB3yIeHt7s7mVlRWbS7VvWrVo0UK8zdXVVdO6XFxc2FyqK42NjWXztWvXsvnEiRPZfN26dXfdtofN5cuXNS3v4+PD5lqrb6X9Uqrclao+b968yeY1a9Zkc6k2skmTJmz+119/sbnk9ddfF28LCgpic6mGWnpO33zzTTaXqmnXr1/P5r169WLzjIwMNi+r1leLa9euGWU9FUmqUdX6nEi1oNJrZyxSvao0nvPy8thcqqyVqnulx9WsWTM2JyJycnJic6l2Wzr/DB8+nM3PnDnD5tI4mTlzJpsvW7aMzSXSayCRxqFUHQ+8Ro0asfmBAwfY/JdffmHzvn37srnelfqNGzcWb/vpp5/Y/PPPP2dzqfI1Li6Ozbt27crmUoXupEmT2Fx6DLNnz2Zz6c8p6H2cvB0+2QAAAAAAAF1gsgEAAAAAALrAZAMAAAAAAHSByQYAAAAAAOgCkw0AAAAAANDFQ99G1aZNGzaX2qik9hDJk08+yeYRERHiz1y4cIHNR48ezeaDBg3StLyfnx+b16pVi80TEhLYHO5dfHw8m2ttl5JyqUVK62sqNS1JpDaO+vXrs7nUXtW+fXvxPqRx8v3337N5586d2fyll15i8/Pnz7O5o6Mjm3t4eLB5amoqm0utP4WFhWwutc5J65ea9kyZ9BjT0tJMav0ODg5s3rZtWzaXzhsWFhZsLjUt9ejRg82lJkEiosjISDafN28em7/wwgtsPmLECDavUaMGm9euXZvNo6Oj2dxYpP1eagrUek5/2EnH3cTERDZftWoVm+vdOiUZM2aMeJs07qRjsrm5tt/XV6tWjc137drF5tJzKr1vHTduHJtLjaJRUVFsrgd8sgEAAAAAALrAZAMAAAAAAHSByQYAAAAAAOgCkw0AAAAAANAFJhsAAAAAAKALM6WUMmhBMzO9t0VXzs7ObL5nzx42P336NJv369ePzcPDw9n8xx9/ZPNJkyaxORHR1q1b2XzDhg1sfvDgQTYfMGCAeB+cX3/9lc179uzJ5lJDQ2UxcFfWldRilp+fz+ZaW6ekBiNp/7a1tWXz5ORkNpfG+c6dO9k8IyODzVu2bMnmUkOa1Izz3HPPsTmRvL+eO3eOzbdt28bmAwcOFO+Ds2TJEjYfNWoUm0uvvfRcBwQEsLnUAiOxt7dn86ysLE3r0YP02KVmoNzcXDZ3cnJic2m/NBapRero0aNs/s8//7D5888/z+ZSc9o333zD5tOmTWNzIqLffvuNzaXzzN69e9lcaqmSzgNSw450rpRoPUZK+/2tW7fYXNrnsrOzDdg6/d0v771eeeUVNh88eDCbP/HEE2yu99h9EFhaaiuSlVq2jPWeyZD14JMNAAAAAADQBSYbAAAAAACgC0w2AAAAAABAF5hsAAAAAACALjDZAAAAAAAAXWi7pP0+9v7777O51PwyceJENl+wYAGbS40LERERbL5o0SI2J5LbPdLS0thca+uURGr3MbXWKVMmtVFJz6HUqCJJTU3VlHt6erL59evX2VzaL+vXr8/mQ4YMYfNPPvmEzd966y02//3339l83759bE4kNxTFxMSw+VNPPSWuS4s1a9awudT4IXFzc2NzqXXKw8ODzZOSktj85s2bmranIrm4uLC5tM316tVjc2m/l8ab1OIiNeBI65k7dy6b161bl82l88kXX3zB5k8++SSbS41qZZ1PpP1SOp9obZ2S2tak5iyJNB6kY6SUV6lShc2llirpeQBtVqxYweYvvfQSmw8bNozNpbEF/5HGnCnDJxsAAAAAAKALTDYAAAAAAEAXmGwAAAAAAIAuMNkAAAAAAABdYLIBAAAAAAC6MFNKKYMWNDPTe1uMQmoD+vPPP9ncwsKCzaWr/cPCwth81qxZbP7uu++yudbmGiK5Cev1119n81u3brG51NYjNbU0a9aMzbOysti8shi4K+uqWrVqbC61P0ktT5GRkZruV2pgyc7OZnOppUpqtZEel52dHZvXqlWLzd944w02l5pMnJ2d2bys2yZNmsTmL774orguTkJCAptLLVhSY5J0LJGOVTVq1GDz2NhYNvfz82PzixcvsrkpjBNHR0c2l44p0nHawcGBzc3N+d+jSY1KUhuVdL8nTpxgc+mYK7VstWnThs3nzJnD5uPGjWPz8vj000/ZXDqfSMcwqRVKGiedO3dm8+joaDY3Fq0tVVevXtVzcwx2v7z3kkjvH7788ks2b9++PZtLYxQqnyHnFHyyAQAAAAAAusBkAwAAAAAAdIHJBgAAAAAA6AKTDQAAAAAA0AUmGwAAAAAAoIv7to1KasdZtmwZm9epU4fNAwMD2VxqkBk6dCib//DDD2wutZ+Uh9Tk065dOzaX2h527tzJ5lJj16lTp9h82LBhbF5ZTKFlR9rPpAaw8rSScRo2bKhp/Y8//jibT5gwgc1r1qypaXuaNGnC5lKLj0RqbCKSW5iGDx/O5p06dWLz0aNHs/mePXvYfMeOHWyemZnJ5t26dWNzY7G2tmZzqQ3IFMaJdD6R2p+kxiA3Nzc2j4+PZ3Npf/Lx8WHzd955h80fffRRNn/kkUfYXDoP9O/fn823bdvG5ikpKWxeHtI46dChA5uvX7+ezdeuXcvmZ86cYfN9+/axuXRudXFxYXOp4SsvL4/Npf1ea17RTO29l7E8+eSTbN63b182j4uLY/PJkyezuam8fg8DtFEBAAAAAEClwWQDAAAAAAB0gckGAAAAAADoApMNAAAAAADQBSYbAAAAAACgC5Nvo7K0tGTzb775hs379eunaf1SS9AzzzzD5seOHdO0fmOSXgNjtS706tWLzUeOHMnmTz/9NJtLLTh6M4X2Cek18vf3Z/PY2Fg2t7W1ZfNbt25p2p5//vmHzaX2KnNz/vcPhw4dYvPx48ez+cGDB9lcapApD19fXza/du0am+fk5Bjlfl9++WU2l1p8pMYhidS0l5yczOZaG81MeZxIj11qYZJaAyXS+eTbb79lc6kZRyK1YHXv3p3Nz58/z+ZZWVma7tfJyUm8LSMjQ9O6pEYwiY2NDZu3bNmSzT/66CM279GjB5tL25+dnc3mUhOedKxNT09nc1MYJ0QPbhuV9LiOHDnC5lIb2pQpU4y1SVBOaKMCAAAAAIBKg8kGAAAAAADoApMNAAAAAADQBSYbAAAAAACgC0w2AAAAAABAFybfRjVq1Cg2nz9/PptL2xkVFcXm3bp1Y/PIyEgDtg5MiSm0h0htN0FBQWx+9epVNk9MTNR0v2+99Rab9+7dm82lppjt27ez+dSpU9n81KlTbC69FlpbdqTnk4joxo0bbB4QEMDm0dHRmu7b3d2dzaX2mmbNmrG51Mzl4eHB5klJSQZs3X+sra3Z3MXFhc2ltq6KpPV8Ymdnx+ZSI5FkxIgRbD579mw2l5q+pH1JGm8JCQlsrrVdzhRVqVKFzaWWKmn/rlq1KptLDXnSfiwday9fvszmqampbG4K5xOiB7eNqnPnzmwuHRdXr16t5+bAPUAbFQAAAAAAVBpMNgAAAAAAQBeYbAAAAAAAgC4w2QAAAAAAAF1gsgEAAAAAALowmTaqsLAwNt+4cSObSw0Yx44dY/Pu3buzeXx8/N03Du4LptAeonWcODs7s7nUeNSmTRs237FjB5tLjU1SC067du3Y/OzZs2zu5ubG5tLzkJyczObGZGVlxeZ5eXlGWb/UUuXo6MjmUtuNtD1169Zl8+PHjxuwdXdnCuNEOn5L+6tWUtvali1b2NzJyYnNjx49yubPPPMMm0sNSVpbs6RxlZKSomk95eHg4MDmUpOc9NxJMjIyNG8TR9qHMjMzjbJ+UxgnRPd/G5XUljd27Fg2nzlzJpubyusBpaGNCgAAAAAAKg0mGwAAAAAAoAtMNgAAAAAAQBeYbAAAAAAAgC4w2QAAAAAAAF1UeBuVtJ5t27axeXh4OJtLrTaNGzdm88uXLxuwdXA/M4W2CmONEx8fHzb/6aef2DwkJETT8uvXr2fzb775hs2l59bV1ZXNpZat2NhYNjem+vXra7pvqZlLq8DAQDaPiooyyvol0j4nvWYP0jiRnDhxgs0feeQRNk9ISGDzp59+WtP6pYYk6TnX2r4lNZ6Vp8VLGrtSe5qNjQ2bFxQUsLnUaiU17VlYWLB5YWGhpuXz8/PZXCLti9L9VrT7vY1K2m9q167N5qdPnzbK+nNycjStxxQ9+uijbH7kyBE217rvGwvaqAAAAAAAoNJgsgEAAAAAALrAZAMAAAAAAHSByQYAAAAAAOgCkw0AAAAAANCFZUXfodSsULVqVTa/cOECm3ft2pXN9W6dkrbf0pJ/KvPy8vTcHLjPubm5sfmVK1fYXGphi4mJYfNPP/2UzXfs2HH3jbuN1C4lteBobbSRmkOkxhkiuQUnMjJS/BljMDfnf0cjvQZaNWzYkM2lx2Vra8vmubm5RtkeUyA1jGVkZLB5YmIim588eZLNe/XqxeZJSUkGbN1/MjMz2dzf35/NpSY0Ozs7TesvD2mMuru7s7l07pOeI+kxSG1UUvuT1HSjtXlHOtampKRoWg9oI+0HZ86cMcr6Bw0axObnz59nc63nPmOSjtV9+/Zl8yVLlrC5dDyMi4sr34ZVAHyyAQAAAAAAusBkAwAAAAAAdIHJBgAAAAAA6AKTDQAAAAAA0AUmGwAAAAAAoIsKb6OSSC07CxcuZHO9G2ckjo6ObP7OO++w+Xvvvafn5oCJsbKyYnOplUxrQ4rU5DJgwAA2P3DgAJv7+fmx+cWLFzXdr9RS5eLiwuYvvfQSm7///vtsLjVOERmvGc7T05PNpdYpqfGuSZMmbC41bUVHR7O51NIibafUCCY1f5kyX19fNpde0+vXr7O5tL9+8sknbB4VFWXA1pWftM9IbWtvvvkmm0+dOtVo2+Th4cHmWhu4JFevXmXz2rVrs3l8fDybS21UDg4ObJ6WlsbmaJ2qHNJYlF5XrdatW8fmI0eOZHNpPyOS20+1kvbN+fPns3n37t3Z/JtvvmFzY43RioRPNgAAAAAAQBeYbAAAAAAAgC4w2QAAAAAAAF1gsgEAAAAAALrAZAMAAAAAAHRR4W1UhYWFbC61TkVEROi5OZplZmay+enTpyt4S8AUubq6snliYiKba23BOXjwIJtLrVMSqXVKIj2u1NRUNpfag06cOKHpfssSFhbG5nv27GFz6TFIrTlSo4jU5HX8+HE210pq+JIa+3Jzc9ncx8fHKNujB2trazaPi4szyvp37tzJ5lu2bGFzad+Q2qK0tsFIr5E0TqT2KqmBTdp+IrmFSdomY7G1tWVzqS1K2p6qVauyudREJrG3t2fzgIAATesBbYzVOiWRzkHSuWb58uXiusLDw9m8rFZETseOHdlc2mc7derE5sY8X1Y2fLIBAAAAAAC6wGQDAAAAAAB0gckGAAAAAADoApMNAAAAAADQBSYbAAAAAACgCzOld1UAAAAAAAA8lPDJBgAAAAAA6AKTDQAAAAAA0AUmGwAAAAAAoAtMNgAAAAAAQBeYbAAAAAAAgC4w2QAAAAAAAF1gsgEAAAAAALrAZAMAAAAAAHSByQYAAAAAAOgCkw0AAAAAANAFJhsAAAAAAKALTDYAAAAAAEAXmGwAAAAAAIAuMNkAAAAAAABdYLIBAAAAAAC6wGQDAAAAAAB0gckGAAAAAADoApMNAAAAAADQBSYbAAAADH9/f/L396/szQC4b2DMVL7Y2FgyMzOjIUOGVPamFMNk4zb+/v5kZmZm0H+m9CICVITIyEgaNWoUNWrUiJydncna2pq8vb3p6aefpmXLltGtW7fKve4VK1aQmZkZrVixwngbrNHkyZPJzMyMduzYUWnbAHdXdAz28/MT97miY3l+fn4Fb939B+e9Bx/GjPEVPacWFhZ08eJFcbmGDRsWL/vHH39U4BaaFsvK3gBTMmbMGEpLSxNvv3nzJs2ZM4cKCgqoUaNGFbdhAJVs6tSpNGXKFCosLKRWrVrR4MGDqUqVKnTt2jXatWsXvfTSS7R48WI6dOhQZW8qPCTi4uJo3rx59M477+h2H9u2bdNt3aYC572HB8aMcVlaWlJ+fj4tX76cJk+eXOr2vXv30pkzZ4qXe6gpMEhhYaF69tlnFRGp3r17q8LCwsreJIAKMW3aNEVEysfHR+3fv59dZuPGjSo8PLzc97F8+XJFRGr58uXlXse9mjRpkiIitX379krbBrg7IlKurq7Kzc1NOTk5qevXr5daxs/PTxGRysvLq4QtrDhF+2xMTIwu68d578GAMfMfY40ZIlI1atRQzZo1U76+vqqgoKDUMkOGDFFWVlbqySefVESktm7dek/3aaiYmBhFRGrw4MEVcn+GwNeoDPTBBx/QunXrKDg4mL7++msyMzMrvi0tLY3eeecdqlu3Ltna2pKrqys9/vjjtHXrVnZdhYWFtGjRImrRogU5OjqSg4MDhYSE0KJFi6iwsLDU8mZmZtS+fXu6du0avfjii1S9enVycHCg0NBQ2r17NxER3bhxg8aOHUu+vr5kY2NDQUFBtG7dOn2eDHhoxMbG0pQpU8jKyop+//13atmyJbvcE088QRs3biQioh07dpCZmRn7mx6i0t/pbd++PQ0dOpSIiIYOHVriaxuxsbHFy2kZZ3f7WlbRmLp9m6ZMmUJEROHh4SW2AUyPvb09vf/++5SRkVH8uhnqhx9+oLZt25KzszPZ2dlRo0aNaMaMGezXS7jvn+fk5NDcuXMpODiYXF1dyd7ennx8fKhbt27svhgZGUlDhgwhHx8fsrGxoerVq9Nzzz1HZ8+e1bTdlaGs8x4Rzn33E4wZfbz00ksUFxdX6nFkZGTQ2rVrqXv37lStWjX2Z7dv304vv/wyNWzYkJycnMjOzo6CgoJo0qRJlJ2dXWr59PR0mjJlCgUFBVGVKlXI0dGR/P39qU+fPnT48OG7bmthYSG98cYbZGZmRs8888w9ffVZs8qe7dwPVq9erYhIeXp6qvj4+BK3paSkqPr16ysiUo8++qh6++231bBhw1SVKlWUmZmZWrhwYan19evXTxGR8vX1VaNHj1Zjxowp/q1Cv379Si1PRKpJkyaqdu3aqmnTpmr06NHqhRdeUFZWVsrOzk4dPXpUhYSEqDp16qiRI0eq4cOHF9//vn37dHte4MH3wQcfKCJS/fv3N/hntm/frohITZo0ib3dz89P+fn5Ff97+fLlqkePHoqIVI8ePdSkSZOK/0tNTVVKaR9nd/ukhIhUu3btiv89d+5c1a5du+LfBt2+DWBa6P//RjE3N1fVrl1bWVlZqbNnz5ZYRvot7YQJExQRqapVq6oRI0aot956SzVs2FARkWrbtq3KyckptZ7b91WllOrbt68iItWoUSP1xhtvqLffflu98MILqlatWmrcuHEllt24caOys7NTVlZWqlevXmr8+PFqwIABysbGRjk5OanDhw/f03Oh5ycbZZ33lMK5736CMfMfY3+ykZaWpuzt7dWzzz5b4vbFixcrIlIbN25UgwcPZj/Z6NKli/Lz81MDBgxQb731lnrttddU06ZNi5/b21+LwsJC1apVK0VEqnXr1urNN99U48ePV/3791eenp7q008/LV6W+2QjOztb9e7dWxGReu2119hPYvSEycZdHDhwQNna2ipbW1v2KyTDhw9XRKRGjBhRIo+MjFRVqlRRVlZWKjo6ujj/9ttvFRGpkJAQdePGjeL8xo0bqlmzZoqI1DfffFNiXUSkiEi98sorJXaQr7/+WhGRcnZ2Vl27dlXZ2dnFt+3du1cRkerZs+c9Pwfw8AoPD1dEpJYuXWrwz2idbCh198mB1nGmdbKhFL5Gdb8oOskrpdTatWsVEalevXqVWIZ747Rnzx5FRMrPz09du3atOM/Ly1NPPfWUIiI1bdq0Uuu5fV9NS0tTZmZmqnnz5io/P7/UtiUlJRX/f0pKinJxcVEeHh7qzJkzJZY7efKkcnBwUE2bNtX+BNxGr8nG3c57SuHcdz/BmPmPsScbSik1aNAgZW1tXeLrac2bNy/+epU02bhw4QL71cSJEycqIlKrV68uzo4fP178C7k7FRQUqJSUlOJ/3znZSE5OVm3atFFmZmbq448/vpeHXW6YbJQhISFBeXl5sQdBpZTKyclRdnZ2ytHRscQLXeTdd99VRKSmTJlSnHXs2FH87t6WLVsUEZX67jsRKXt7e5WRkVEiz8/PV5aWloqI1IULF0qtr1atWsrf39/gxwtwpwYNGhT/dsZQxp5slGecYbLx4Lr9JK+UUq1bt1ZEpHbv3l2ccW+chg0bJk6cIyMjlbm5uapVq1aJ/M59NSMjQxGRCg0Nvev1C/PmzVNExP6GXymlxowZo4hInTx5ssz1lEWPycbdzntK4dx3v8GY+Y8ek41du3YpIlKzZ89WSil19OjREudAabIhSUpKUkSkhg4dWpydOHFCEZEaMGDAXX/+9slGbGysql+/vrKyshLHc0VAG5Xg5s2b1L17d7py5QpNnDiRnn/++VLLnD17lrKzs6lNmzbk6upa6vZOnTrRjBkz6MiRI8XZ0aNHydzcnNq1a1dq+fDwcLKwsCixfJG6detSlSpVSmQWFhZUvXp1ysrKooCAgFI/4+3tTQcOHDDo8QJwlFJERJV67UJ5xhk8PGbPnk2hoaE0btw42r9/v7ivHj16lIj+Pc7eqV69elSzZk2KiYmhtLQ0cnFxYddRpUoV6tatG/36668UHBxMvXv3pjZt2lDLli3J3t6+xLL79u0jIqJjx46x1y+dO3eOiP79fnpQUNBdH2dZY7BWrVqlskmTJonXTUkMOe8R4dx3v8OYMd6YISJq27Yt1atXj5YtW0Zjx46lpUuXkrm5Ob344otl/lxWVhbNnz+fIiIi6Ny5c5SZmVl8ziUiunTpUvH/N2zYkIKDg2n16tUUHx9P3bt3p7CwMAoJCSFra2t2/WfPnqXWrVtTVlYWbdy4kTp27Kj5sRkLJhsMpRQNHjyYjhw5Qj169KDp06ezy6WnpxMRkaenJ3u7l5dXieWK/t/NzY2srKxKLW9paUkeHh6UmJhY6jZnZ2f2PiwtLcu87aGvW4N74u3tTZGRkZSQkFBp21CecQYPj9atW9Ozzz5L69atozVr1lC/fv3Y5QzZj+Li4ig9PV1840T078WyM2fOpO+++44++OADIiKytbWlvn370qxZs6hq1apERJScnExEREuXLi1z+2/cuFHm7UUmTZpUKtuxYwft3LmTRo8eXWqbby9AMISh5z0inPvudxgzxhkztxs2bBhNmDCB/vzzT/ruu++oc+fO5OvrKy6fl5dHHTp0oIMHD1KjRo2oX79+VLVq1eLxMWXKFMrJySle3sLCgrZt20ZTp06ldevW0YQJE4iIyMnJiYYMGUIzZswgBweHEvdx7tw5SklJoeDgYGrevHm5H5tRVNpnKibs/fffV0SkGjdurDIzM8Xlij7WatOmDXv7n3/+Weo7dm5ubsrc3Fzl5uaWWj4vL09ZWFgoZ2fnEjkxX/kown0lpUjRBa8A5VV0gbghH90W2blzpyIi9d5777G3u7i4aPoaVXnG2cqVK8WP/1NTU/E1qvsY3fGVEKWUioqKUlZWVqpWrVoqJyeH/UpI0XUBUVFR7Hp9fX0VERWXEihV9vFVKaXi4uLUN998ozp16qSISD322GPFtxVdjHn8+PHyPVADGPNrVIae95TCue9+gzHzHz2+RqWUUteuXVNWVlaqZs2aiojUmjVrim/jvkZVdO0MV097+fLlMvd9pZQ6f/68+vLLL1WLFi0UEalBgwYV33b716hmzJihiEgFBweXuD6moqH69g7ff/89ffjhh1StWjX65ZdfyNHRUVy2Xr16ZG9vT8eOHaPU1NRSt2/fvp2IiJo1a1acBQcHU2FhIe3atavU8rt27aKCgoISywNUpqFDh5KVlRX9+OOPdPr06TKXLfotTNHXKuLj40stExUVxf4BMQsLCyIiKigoKHVbecZZWdsg/eHBsrYBTFvt2rVp5MiRFBMTQ59++im7THBwMBER+xfio6KiKCEhgWrVqlXmb2jv5OPjQ88//zxt3ryZ6tSpQ7t27aKUlBQiImrVqhURUXFFqynTct4jwrnvQYAxY1zVqlWjrl27UkJCAnl4eFCPHj3KXD4qKoqIiHr37l3qtp07d971/gIDA2nYsGG0c+dOcnR0pIiICHa5iRMn0pw5c+jo0aMUHh7OfnpYISptmmOCDh48qGxtbZW1tbXas2ePQT9T1Mjx+uuvl8ijoqKUs7Oz2MjRokULlZWVVZxnZWUVz1C5Rg78dgcqy/Tp0xURKX9/f/X333+zy9z+R/1yc3OVk5OTcnZ2LtFgcvPmzeI/bnTnPvvbb7+VeVG51nF2+fJlZW5urgIDA0uMs+TkZBUcHMyOqYULF5Z5UTmYBmJ+S6vUv6+ti4uLcnV1Ve7u7qV+S1vUUuTv768SExOL8/z8/OLq5bs16yQmJrLtTBkZGcrT01NZWFio9PR0pdS/F3m6uLioqlWrqgMHDpT6mYKCgnv+FM0Yv6Utz3lPKZz77icYM//R65MNpZSKjo5WERERpbad+2SjqFr6zTffLLHshQsXij8xun3fj46OZi+Mv3TpkrKyslJVq1Ytzrjq24ULFyozMzPVoEEDdfny5fI85HuCazb+v8zMTOrRowfdunWLWrRoQVu3bhX/MBHRv3+4ZsiQIfTxxx/T7t276bPPPqO///6bwsPDKSkpidasWUOZmZn02WeflbgQ6bnnnqOff/6Z1qxZQ0FBQdSzZ08yMzOj9evXU0xMDPXt21e8KA+gMrz77ruUn59PU6ZMoRYtWlBoaCiFhISQo6MjXbt2jXbt2kXnz5+nkJAQIiKysrKisWPH0uTJkyk4OJh69epF+fn5tHXrVvL29iZvb+9S99G6dWuyt7enefPmUXJyMlWvXp2IiEaNGkXOzs6ax5mXlxcNGjSIVqxYQU2bNqWnn36aMjIy6Pfff6fHHnus+MLH24WHh5O5uTlNnDiR/vnnn+JPR/73v//p8bSCkbm5udG7775b/F3mO4WGhtKECRPok08+oUaNGtGzzz5LDg4OtHHjRjp58iS1adOGxo8fX+Z9XLp0iVq1akUNGjSgZs2akY+PD2VkZNCGDRvo6tWr9Prrr5OTkxMREbm7u9O6deuoV69e1KpVK+rYsSMFBQWRubk5xcXF0b59+yg5Obli/7DWHcp73iMinPseABgzxlWrVi32wnNOt27dKDAwkObOnUsnT56k4OBgiouLow0bNtDTTz9NcXFxJZY/fvw49erVi5o3b06NGjUib29vun79Ov3888+Ul5dHb7/9dpn3N3LkSLKxsaGXX36Z2rVrR9u2bSMfH59yP1bNKnx6Y6KKZoKG/nf7jDM1NVVNmDBBBQYGKmtra+Xs7Kw6deqkNm/ezN5XQUGBWrhwoWrevLmys7NTdnZ2qlmzZuqzzz5j/9DKnfd3O/x2ByrK6dOn1euvv66CgoKKe/Q9PT3VE088ob788kt169at4mULCwvVzJkzVUBAgLKyslI+Pj5q/PjxKisrS9xnN27cqFq1aqUcHByKx9ntv33SOs5ycnLUhAkTVI0aNZSVlZWqXbu2mjFjhsrLyxPH1KpVq1STJk2Ura1t8TaAaSHht7RKKXXr1i3l7+9f/Nrd+QfKlPr3N4phYWHK0dFR2djYqIYNG6pp06aV+FsNRe7cV1NTU9WUKVNUeHi48vb2VtbW1srT01O1a9dOfffdd2y1Z0xMjHrttddUYGCgsrGxUVWqVFH16tVTAwcOVBEREeV+HpS699/S3st5Tymc++4XGDP/0fOTDYlUfRsXF6eee+455e3trWxtbVXDhg3VzJkz2XNUfHy8mjhxogoNDVXVq1dX1tbWqkaNGuqJJ55Qv//+e4n1cp9sFFm1apWysLBQ/v7+JT551JuZUrf1bAEAAAAAABgJLhAHAAAAAABdYLIBAAAAAAC6wGQDAAAAAAB0gckGAAAAAADoApMNAAAAAADQBSYbAAAAAACgC0w2AAAAAABAFwb/BXEzMzM9t+O+16hRIzZv1aoVm3fp0kVc14EDB9h8zpw5bC79qRStf0IlICCAzRs3bszmtWvXZvPCwkI2P3jwIJtfuHCBza9evcrmElP4kzEYJ+Xj7+9f2Zvw0IiJiansTdA8Tor+mvudpL8knJ2drXmbtKhatSqbX79+Xdf7nTx5Mpv/888/4s9s3ryZzW/cuMHmjo6ObF6vXj0279q1K5s3aNCAzX/77Tc2X7VqFZtr5ebmxuYpKSma1mMK5xMiIg8PDzaXxkROTg6bx8fHs7m1tTWbOzg4sHlqaiqbG4udnR2bax3THTt2ZPN58+aJP9OyZUs2l16DO//KdxHpr3lL658/fz6b79y5k83d3d3ZPDk5mc2rV6/O5rm5uWwujfX9+/ezuSFjBZ9sAAAAAACALjDZAAAAAAAAXWCyAQAAAAAAusBkAwAAAAAAdGHwBeIPGysrKza3t7dnc+kCV2k9CxcuFO87OjqazaULr43l0qVLbJ6VlcXmXl5ebB4eHs7mgwYNYvOEhAQ2P3r0KJv//PPPbA73Trpw11gXS0oXNQKURbpo1FgXq0rH79jYWDbX+0Lw+vXrs7l0YeiPP/4orks6B0mkC8cPHz7M5tLx3sbGhs1ffvllNpcuEDc3538nKl2AfurUKTb39fVlc+kiX1MhXfQrHZOlC+Slshrpot+CggI211qOYGnJv810cXFhc+n9hnQhu1Rg07x5czYfMGAAmxMROTk5sbm0j0glOdJ4bNOmDZvv2LGDzZctW8bmH3zwAZtLpNdSuhBcKueRXgND4JMNAAAAAADQBSYbAAAAAACgC0w2AAAAAABAF5hsAAAAAACALjDZAAAAAAAAXZgpA2tmpJYaraRmCaltRGpgunXrFpsbqzVHahlo3bo1m2dmZrL5tWvX2DwyMlK87/T0dDY31mPTSnrtq1SpwuY1a9Zk85CQEDZ/8skn2Vx6rqdMmcLmX331FZtXJGONk8oiNYQYa58cPnw4m2/dulXTeqD8YmJiKnsTyNPTk82l46VEOqZIjUrScdfb25vNpfOV1KAnNe/k5+ezeWBgIJv7+Pho2p5t27axuTE1bdqUzY8dO8bmjz/+OJv37duXzWfNmsXmGRkZbH758mU2r169OptL+4T02kjvMSqahYUFm0vvjaTHr3VsgfFJ740GDhzI5tL58tFHH2VzqblMK2dnZza/l/cB+GQDAAAAAAB0gckGAAAAAADoApMNAAAAAADQBSYbAAAAAACgC0w2AAAAAABAFxXeRiWtR2rxkBqP3Nzc2DwpKYnN09LS7r5xt7GysmJzqTUrLy9PU15QUCDed2W1ThmL1Jgivca+vr5sLjWynDt3js2lhpiKdL+3UdnY2LC51M52+vRpo6zfy8tL03qg/Eyhjcrf35/NpTHcvn17NpdamKytrdlcavCRlnd1dWVzqZUlNzdXUy61vzk6OrK51JDk4eHB5kTy6y2NRem+pfYniXSurFatGptLx4D9+/ezeY0aNdhcOudmZ2ezudQkaSrnYemcYmtry+bSdufk5Bhtm8C4pMax3r17s/maNWuMcr/u7u5srrXVCm1UAAAAAABQaTDZAAAAAAAAXWCyAQAAAAAAusBkAwAAAAAAdIHJBgAAAAAA6IKvB9KRdNW6lHt7e7N5hw4d2HzPnj1sfuTIEQO27j9a26XgP1Lji9TIcuHCBTaXWlSk9cO9k8Zh9+7d2fzMmTOa1oNGFCCSWwOllr7Dhw9rWn9+fj6bS/ul1KAntU5J54FJkyax+fTp09lcaqGR7jcoKIjNpcYmIiJ7e3s2z8jI0JRLrUhSu5S0nqtXr7L5xYsX2Vxy6dIlNpeaJKXn4X4lNZOB6ZLG76lTp9jcWK1Tkjp16rC51EZVs2bNct8XPtkAAAAAAABdYLIBAAAAAAC6wGQDAAAAAAB0gckGAAAAAADoApMNAAAAAADQRYW3UUmk9pCUlBQ2l1pwpKvl3d3d2VxqOZHuF4xPaoiRmmlAP1JjmDRO+vfvz+arV6822jbBgycrK4vNra2t2TwtLY3NXV1d2VxqrJNapwICAthcajGUjllbt25l8/Xr17P5yJEj2TwqKorNo6Oj2bwsgYGBbH79+nU2v3LlCptLrVNeXl5sfu3aNQO2zvikpjBpX5Fey/tVlSpV2DwzM7OCtwTuJI1rqXX18uXLbC7ty6mpqWzu4eHB5mW12GlZjyHwyQYAAAAAAOgCkw0AAAAAANAFJhsAAAAAAKALTDYAAAAAAEAXmGwAAAAAAIAuTKaNSiI1YyQmJrL56NGj2fyJJ55g86NHj7L59u3b2XzTpk1s/qA1WgDc7o8//mBzqa2nbt26bD5lyhSjbRM8eKSWlRs3brC51L6itd1FaluTSI0/UsOT1MzUoUMHNpdaazIyMtjc39+fzcv6Genc6ujoyOZmZmZsfuzYMfG+OTVq1GDzS5cuaVqPVgkJCWwuNaCZOjs7OzavXr06m6ONqvLZ2NiwuXRcktrzbt68qel+k5KS2Fwa69LxVsoNgU82AAAAAABAF5hsAAAAAACALjDZAAAAAAAAXWCyAQAAAAAAusBkAwAAAAAAdGHybVSenp5s3rBhQzaXmiUuXrzI5oWFhWwutQZIjRxoo4IHmdTmJjXRSC0a0vgBICLy8vJi87S0NDbPyspic6ndpWrVqmxua2vL5vHx8WyenZ3N5qGhoWweExPD5rVr12Zzya1bt9i8rHYaqYVIesxam2i0NtpI51atpO2XnqP8/Hw2l9qxTJ20D0rvdaDySS15UmNc48aN2VxrA5x0Pq5ZsyabS8fblJQUTfdbYhvK/ZMAAAAAAABlwGQDAAAAAAB0gckGAAAAAADoApMNAAAAAADQBSYbAAAAAACgiwpvo5Laonx9fdm8Q4cObP7CCy+w+VdffcXmS5YsYXOp0SEvL4/NpfYqgAdBs2bN2Hz69Ols3r59ezaX2jUAiOR2lHPnzrG5i4sLm9evX5/NIyMj2VxqWbGwsGBzyfPPP8/m0nlp4MCBbB4XF6fpfiWpqanibdI5V2ryqlevHptL58To6Oi7bF1JUiuUVlLrlIeHB5sXFBSw+YPW3iS9TlD5kpKSNC0vnUcdHBzYXBrTUnObdJzUo3UVn2wAAAAAAIAuMNkAAAAAAABdYLIBAAAAAAC6wGQDAAAAAAB0gckGAAAAAADoQrc2Kqndo2bNmmw+duxYNnd3d2fzDRs2sPnx48fZvKy2DoCHjY2NDZt//vnnbL5q1So2R+sUlIfU6pebm8vmly9fZnOpacnLy4vNpTYqqcEoMzOTzaU2qvfff5/Nr127xuYBAQFs7ujoyOYnTpxg87IaiLS2E509e1bT8lppbeBq2LAhmycnJ7O5j48Pmx86dEjT/ZoKaV++cuVKBW8J3CutrXdS01tISAibS21XsbGxmu5XOq7m5ORoWs/t8MkGAAAAAADoApMNAAAAAADQBSYbAAAAAACgC0w2AAAAAABAF5hsAAAAAACALnRro2revDmbh4WFsbmnpyebR0ZGsvmKFSvYXGobgQeHuTnmyPdqyJAhbC411yxbtkzHrQH4V35+PptbWVmxudS+0qxZMzY/f/48m3t7e7O5NE6k7ZHWX79+fTaX2hO7du3K5vHx8WwutVcRyc+R1IwjNc5IxwbpeCw1jkntStLyUn7z5k0219o65evrq2n5iia1Tjk7O7O51DSYmJhotG2C8pFa6aT3v1evXmVzqV0qKytL0/ZI+750zLgXeNcGAAAAAAC6wGQDAAAAAAB0gckGAAAAAADoApMNAAAAAADQBSYbAAAAAACgC4PbqKT2DTs7OzaX2jS6devG5t9//z2bb9++nc2lq+ULCgrY3NRITSBlkVo5lFKa1mNmZqb5vjlubm5sXqNGDTavW7eupuWl1pI6deoYsHVAROTi4sLmkyZNYvPXXnuNzTMyMoy1SQAi6ViQmprK5jdu3GDzv//+m82zs7PZPD09nc0HDhzI5pMnT2bz5ORkNndycmJzSUJCApsHBQWx+Z49e8R1Va9enc2lZhytpCasV155hc1r1arF5vb29mwunTeeeOIJA7buP1JrVlxcnKb1mAqt+zJUPqmVzt/fn807d+7M5iEhIWwuNZd9+umnbH7mzBk2v3XrFpvfC3yyAQAAAAAAusBkAwAAAAAAdIHJBgAAAAAA6AKTDQAAAAAA0AUmGwAAAAAAoAuD26gcHBzY3M/Pj819fHzYPCAggM2feuopNpeak65evcrmUkvVzZs32Vxv0vMwYMAA8WektiVbW1s2X7lyJZvv2rWLzaXGLq1tV1JDkdQo07x5czYPDw9n88aNG7P5sWPH2BxKq127NptXq1aNzV944QU2379/P5tL7RdaxcbGsvnChQvFn3F3d2fzIUOGsHlubi6bS/u91LT32WefsfngwYPZPCIigs1nz57N5ocOHWLz/Px8Nn+QXLp0SdPy0n4stScmJiayuXSsOXLkCJs3bdqUzaXjvaUlf6qVjpVaj3FS2wwRUWhoKJtLx2PpXC+RzgONGjVi82eeeYbN9+7dy+YHDx5kc6mJTNr+rKwsNpdasEzd008/zebS8QYqX2RkJJuPHTuWzaU2vM8//5zNpVbXAwcOGLB1/5FaLKU2LUPgkw0AAAAAANAFJhsAAAAAAKALTDYAAAAAAEAXmGwAAAAAAIAuMNkAAAAAAABdmCmpaugOFhYWbC61bHh6erJ5zZo12VxqqZJaQh599FE237Ztm6b81KlTbJ6ens7mWnl4eLB5u3btxJ/p2bMnm/fp04fN165dy+a//vorm2/fvp3Nc3Jy2FxqfJHadzp27Mjm1atXZ/PTp0+zudSm9fvvv7P5yZMn2bwiSe1plcXGxobNGzRowOatW7dm8+eee47Np02bxuabN282YOvu7pVXXhFvkxp4xo8fz+ZSi5TUCLR8+XI2l9rili5dyubTp09nc6kFS28GHvJ1JbWdSC1SUuOR1DAmHXel51xqkUpNTWVzqfFMOq5L+56xmoPGjRsn3jZz5kw2nzp1qqbc2dmZzf/++282l8bJ0KFD2fzo0aNsLjXVSW1Ujo6ObC61UUktb6YwTojkdi1pX75165aemwP3QHrvIr1f3rBhA5v//PPPbJ6cnMzm0hgyFkPGCj7ZAAAAAAAAXWCyAQAAAAAAusBkAwAAAAAAdIHJBgAAAAAA6AKTDQAAAAAA0IXBbVSV1bLj7+/P5lJrjtTYJF3t/+6777L5gQMH2Dw7O5vNJdLzJrV4ERE9++yzbC5tq9SmU6VKFTa/efMmm0uPTWq3uHDhApv/888/bL5nzx42j4qKYvMrV66wudQUpvW10YOptVEZywsvvMDmc+bMYfPAwEA219ryZm1tLd526NAhNn/kkUfYPCUlhc2llpp9+/ax+ZdffsnmUhuatB9XFlNo2bG3t2fzoKAgNpdea0ndunXZ/Ny5c5rWo1XTpk3Z/IcffmDzkJAQNpeahvz8/Ni8rH3sxIkTbC41Q0rHb+m+f/nlFzaXWgY/+ugjNtfKycmJzaX2ROk8IzGFcUIkN6Vdu3aNzfPy8vTcHLgHUovU4sWL2XzTpk2a1i+18EmSkpI0LS9BGxUAAAAAAFQaTDYAAAAAAEAXmGwAAAAAAIAuMNkAAAAAAABdYLIBAAAAAAC6wGQDAAAAAAB0IfevmgipItHb25vNpTo8KysrNrexsWHzsqpptXBwcGBzqRqUiKh+/fps7ubmxubSY7OwsGBzR0dHNt+5cyebf/XVV2wu1aZJdcWjR49mc6mOUqqJO3z4MJuDfqTxpnVcadWiRQvxNldXV03rcnFxYfNhw4axeWxsLJuvXbuWzSdOnMjm69atu+u2PWykmurIyEhN65HOD1IFtXQMlWqRpX0mLS2NzYODg9lcquKVasWl+lKpTlZ6Hojkc5BEqh+eOXMmm0u1vp999hmbSxXRv/76qwFb9x/pmCTtQ9J5VRrnpiI1NZXNUXF7/5Gq4qVzxKhRo9j8+++/Z3OtVbbSeTonJ0fTegyBTzYAAAAAAEAXmGwAAAAAAIAuMNkAAAAAAABdYLIBAAAAAAC6wGQDAAAAAAB0YfJtVNWqVWPzsLAwNvfx8WHzmzdvsrnUpiO1UUktJ4888gibt2/fns2HDx/O5kREHh4ebJ6YmMjm69evZ3OpMaVly5ZsXrVqVTYfO3Ysm0ttQNL2u7u7s7nUBnL58mU2l5psQD9t2rRhc2n8WFtba1r/k08+yeYRERHiz1y4cIHNpdazQYMGaVrez8+PzWvVqsXmCQkJbA6Gu3HjhqblpeO6dKyUmn0k0jFU8vTTT2taT506ddhcap3y8vJi8927d4vbtHfvXk1537592fzxxx9nc+lcLB0zpOdIOj8kJyezudbmsvj4eDaXjj2mIisrS9PyAQEBbB4dHW2MzYF7sGrVKjZXSrH5tWvX2LxRo0Zsbmtry+bHjx9nc6l1SnrfLb3/NQQ+2QAAAAAAAF1gsgEAAAAAALrAZAMAAAAAAHSByQYAAAAAAOgCkw0AAAAAANBFhbdRmZvz8xsHBwc2r169OptLTTEXL15kc+lq/KioKDZ3dHRk8xYtWrD5sGHD2Lxhw4ZsLjVIEREdOnSIzc+fP8/mo0aNYnOp9UN6jtzc3Ni8VatWbC6R2kN27drF5tu2bWPzw4cPs7nU3AD3ztnZmc39/f3ZfMOGDWwuNTOFh4ez+bfffsvm48ePZ3Mioq1bt2rapoMHD7L5gAEDxPvg/Prrr5rWDxVPap2ysbFhc6mVJTAwkM2l84OLiwubnzt3js2lthmpMXDHjh1sPn/+fDYnIpozZw6bx8TEsLm0H0vNiklJSWwuHQMyMjLY3Fi8vb3ZXGo3LKvx7n505cqVyt4EEEhtqQcOHGDz7du3G+V+LSwsNC0vtfndC3yyAQAAAAAAusBkAwAAAAAAdIHJBgAAAAAA6AKTDQAAAAAA0AUmGwAAAAAAoIsKb6OSGo/69OnD5k8++SSb165dm82lJg2pjWrQoEFsHhwczOaPPvoomx89epTN16xZw+arVq1icyKiuLg4NjczM2NzqWXD2tqazTt37szmdnZ24jZxpFYoqY1q9+7dbB4ZGalp/aCf999/n80DAgLYfOLEiWy+YMECNh88eDCbS40wixYtYnMiosLCQjZPS0tjc62tUxKpjUraHqh4VapUYfM2bdqw+caNG9lcaiuU2tPc3d3ZXGpIe/HFF9m8f//+bP7TTz+x+dKlS9mcSG6WkY67UutUQUEBm0tNN9K2Ss2TUlNlZmYmm9vb27O5dN6TSNtzv8rOzta0vJeXF5tbWVmxufT+RPL222+zufTea9KkSWwujd1+/fqxuTTmhg8fzuZE8nugEydOsLnUlnr27Fk2z83NZfM33nhD3CYtpDZJS0v+rb70Xk06jt3LOQ6fbAAAAAAAgC4w2QAAAAAAAF1gsgEAAAAAALrAZAMAAAAAAHSByQYAAAAAAOhCtzYqGxsbNpeucm/cuDGbe3h4sLnUpNGkSRM2l1qkfH192TwmJobNlyxZwua//PILm//9999sXp6r+qU2KqkxRWpQkF4Dya1bt9j8+vXrbC61YUgNK9JzIb3GWVlZbA6Gk5pGWrZsyeZSm9uECRPYPCwsjM1nzZrF5u+++y6bSw04Zfnrr7/YvFmzZmwu7d/SMeCtt95i8++++47Nsb+WJrUSOjo6svnNmzfZPCkpic2lBiPpNXVxcWFzqdlM2h5pf23dujWbd+zYkc0nT57M5lOmTGHz8pCaEmvVqsXmrq6ubH7t2jU2d3JyYnPp/KD1nCi9BikpKZrWc7+Oz9DQUDa/dOkSm0vP15UrV4yyPYGBgWzeu3dvNpfG+ssvv8zmnTp1YvPXXnuNzRcvXszmZZGayX7//Xc2f+yxx9g8JCSEzaOjo9n8//7v/9j8+eefZ/OEhAQ2T09PZ3OJ9P5aOq5KjXGGwCcbAAAAAACgC0w2AAAAAABAF5hsAAAAAACALjDZAAAAAAAAXWCyAQAAAAAAujBTSilDFrS3t2dzqVWkT58+bN61a1c2r1atGptLV8tLeU5ODpvHxsay+TfffMPm27ZtY/MjR46weXnapbSS2qjatWvH5lIDl9QacfHiRTY/cOAAm58/f57NPT092XzMmDFsLjVASNuzcuVKNpeavyqS9BpVFmlcLVu2jM3r1KnD5tI+k5+fz+ZDhw5l8x9++IHNjTl+3njjDTaXxsmXX37J5jt37mTzP//8k81PnTrF5sOGDWPzymLgIV9Xzs7ObJ6RkcHmTZs2ZfNz586xudQKJZ0fqlSpwuZSS4zUetiqVSs2P336NJtLLYYLFixgc6nlUTq/ERHZ2dmx+YwZM9jc29ubzTdt2sTmV69eZfOxY8ey+aJFi9hcalE6ePAgm/v4+LC51Mgj7VsSUxgnRNrPKVLTYF5eHptL7ZTJyclsLu3js2fPZnOpBUtql9q3bx+bS+esr7/+ms2l/V7rfkBE9Prrr7P5U089xebz5s1j8y1btrC59L5SGhPdunVj8+rVq7O5paW24lnpuZOaTw0ZK/hkAwAAAAAAdIHJBgAAAAAA6AKTDQAAAAAA0AUmGwAAAAAAoAtMNgAAAAAAQBcGt1G1b9+ezaWmFamxQGq7kTZDapa4fPkym69YsYLNIyIiNK1HalCAu5PaLRo3bszmoaGhbN6wYUM2X7x4MZvv3r3bgK3TV2W1UUltE1LbWr9+/TStPyYmhs2feeYZNj927Jim9RuT9BoYq12mV69ebD5y5Eg2f/rpp9k8NzfXKNujlSm07EhtJ7du3WJzqQ1NapZJTExkc6nVSjo2Sc13UnuM1FIljZO4uDg2r4jxM2DAADb/6aef2NzPz4/NpUYwqe1Kut9mzZqxeWpqKptL+5DW/VtqaZKa9ipajRo12FxqnZKa1U6ePGmU7ZGaOoOCgthcakg6c+YMm0tjUXo9pGbSpKQkNi8P6TkNCAhg84SEBDaXjlc9evRg8/fff5/Nw8PD2TwlJYXNpfY/6f21VmijAgAAAACASoPJBgAAAAAA6AKTDQAAAAAA0AUmGwAAAAAAoAtMNgAAAAAAQBcGt1FJrTa9e/dmcxsbGzbPyclhc+nq/U2bNrH5F198oWk9aWlpbA4PDlNo2amsNqpRo0ax+fz589lc2s6oqCg279atG5tHRkYasHVgSkxhnEjNNadPn2ZzqXlIarrJzMxk8z59+rD5e++9x+Y1a9Zk8+3bt7P55MmT2XzXrl1sbixSIw8Rkb29PZtLTVhSK5TUFCYdM2xtbdlcahn09PRk8/Xr17O59Lik/VtaXnpvYCptVHqfU6Sx2L17dzaXWveksRIfH8/mzz33HJvv2bOHzdu0acPmUjOcMRtFfXx82Fx6bFrVr1+fzR0dHdn87NmzbC4d9yTSmJAaQv/44w82RxsVAAAAAABUGkw2AAAAAABAF5hsAAAAAACALjDZAAAAAAAAXWCyAQAAAAAAujC4jUpqorC2tmbzixcvsvmhQ4fYXGqXOnz4MJtLDRKm0LQClcMUXnu9m0PCwsLYfOPGjWxepUoVNj927BibSw0kxmrdgMpnCuOkVq1abH7jxg02l5plpMcitVdJ7WwDBw5k88TERDYfPnw4m//yyy9sLp0nc3Nz2bwiWFlZacqdnJzYXHpv4OLiwuaXLl1i88LCQjYvKChgc2OR9hVjthndC63nFEtLSzaX2rWefPJJNl+xYgWbS2Pi3LlzbN63b182l9qrkpOT2Vw6NlhYWLC5q6srm5f1ukrHk+zsbPFnjMHLy4vN8/Ly2DwpKUnT+r29vTWtp1q1amwutb2ijQoAAAAAACoNJhsAAAAAAKALTDYAAAAAAEAXmGwAAAAAAIAuMNkAAAAAAABdGNxGlZmZyebS1eyffvopm69atYrN09PT2Vy6Gh/gTqbQsmOsNippPdu2bWPz8PBwNpeaPRo3bszmly9fNmDr4H5myuPE39+fzaUGo3r16rH53Llz2bxu3bpsLrUnTp8+nc3PnDnD5nFxcWyulYODA5tnZWVpXlfz5s3ZXDrnRkVFaVq/1Dol7WfS/UqaNWvG5idOnGBzqXWpYcOGbB4ZGcnmerdgGUoaK25ubmwuvVeTWre+/fZbNu/atSubHzlyhM07d+7M5lKLWWxsLJvfT6TnVGqXko4P0j7r6+uraT0SGxsbNpcawaTjzNWrV9kcbVQAAAAAAFBpMNkAAAAAAABdYLIBAAAAAAC6wGQDAAAAAAB0gckGAAAAAADowtLQBb/77js2X7x4MZtL7R5paWmG3mWFkJoerK2t2VxqH7h58yab5+bmlm/D4KEm7ZdVq1Zl8wsXLrC51Ciid+uUtP2WlvwhB61zDxepdcrcnP/9l7R/nDt3js0fffRRNpdaX6Tz2+bNm9lc4uPjw+ZSm5aVlRWbS+NEen4KCwvFbTp8+DCbBwUFiT+jhXROr169OptrbaOS2o8k1apVY/PTp09rWo+pkNrEpNdVIo0hb29vNpcaj8aOHcvmKSkpmnKJ9PolJiayeZUqVdg8OzubzaVjQFnc3d3Z3MPDg81jYmLYvH79+mwuvTZnz55l85CQEDY/dOgQm0tjUXrfIDWdBQYGsrkh8MkGAAAAAADoApMNAAAAAADQBSYbAAAAAACgC0w2AAAAAABAF5hsAAAAAACALgxuo1q6dCmbSw0PptYuI7V42NjYsHmTJk3YvEuXLmz+22+/sbnUDgBQHsnJyWy+cOFCNo+MjNRzc0SOjo5s/s4777D5e++9p+fmgImJjY01ynqktr8dO3awudQaePLkSTa3tbVlc6ltLT4+ns2l1honJyc2l86fWpuciIg8PT3Z/NSpU5rXxbG3t2fz1NRUNq9Xrx6bSw0+Eum1l5p0bty4webSPmEqpNYpPz8/NpeaQCXS8/jyyy+z+c6dO9lcaoXKzMxk86ZNm7K5tF+2bNmSzd944w02f/7559lc2l+JiHx9fdlcOo9K52OJg4MDm584cYLNpXY7re8rpWaxunXrsrnU8peTk6Ppfm+HTzYAAAAAAEAXmGwAAAAAAIAuMNkAAAAAAABdYLIBAAAAAAC6wGQDAAAAAAB0YaaUUoYsaGFhweaFhYVG3SBTERAQwOZSI8Lff//N5lFRUUbbJiibgbuyrqSWGmPp06cPm0dERLB5fn6+npujmdQQ8u2331bwljy8THmcSOcZqXknOjqazVevXs3m//vf/9j80qVLbC6dBxISEthcaneR2mOk1rbBgwezudQ6VxZLS750Usr9/f3ZvEaNGmwuNfIcO3bsrtt2u6CgIDY3VmuWVqYwToj0P6e0b9+ezf/55x82t7a2ZnOpdUpqYnNxcWFzqdFNajcbMGAAm0vvvQ4cOMDmZZHGhLFa9bSSmr+k10Yao9IxQGpvdXV1ZfOrV6+yeYl13nUJAAAAAACAcsBkAwAAAAAAdIHJBgAAAAAA6AKTDQAAAAAA0AUmGwAAAAAAoAuD26gAAAAAAAC0wCcbAAAAAACgC0w2AAAAAABAF5hsAAAAAACALjDZAAAAAAAAXWCyAQAAAAAAusBkAwAAAAAAdIHJBgAAAAAA6AKTDQAAAAAA0AUmGwAAAAAAoIv/B20QZpqFR7goAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a sample image\n",
    "sample_image = x_train[0]\n",
    "img_arr = img_to_array(sample_image) \n",
    "img_arr = img_arr.reshape((1,) + img_arr.shape)\n",
    "# Apply different augmentations\n",
    "augmented_images = []\n",
    "# For the other augmentations, we can use the existing datagenerators\n",
    "\n",
    "# Apply each datagen separately to the same image\n",
    "augmented_images.append(img_arr)  # Original image\n",
    "\n",
    "# Random Noise\n",
    "augmented_images.append(datagen_rand_noise.flow(img_arr, batch_size=1))\n",
    "\n",
    "# Radial Noise\n",
    "augmented_images.append(datagen_radial_noise.flow(img_arr, batch_size=1))\n",
    "\n",
    "# Flip\n",
    "augmented_images.append(datagen_flip.flow(img_arr, batch_size=1))\n",
    "\n",
    "# Zoom\n",
    "augmented_images.append(datagen_zoom.flow(img_arr, batch_size=1))\n",
    "\n",
    "# Mask (Cutout)\n",
    "augmented_images.append(datagen_mask.flow(img_arr, batch_size=1))\n",
    "\n",
    "# Random Noise + Zoom\n",
    "augmented_images.append(datagen_rand_noise_zoom.flow(img_arr, batch_size=1))\n",
    "\n",
    "# No Augmentation\n",
    "augmented_images.append(datagen_rand_noise_mask.flow(img_arr, batch_size=1))\n",
    "\n",
    "f, xyarr = plt.subplots(2, 4, figsize=(10, 5))\n",
    "for ax in xyarr.flat:\n",
    "    ax.axis('off')  # This removes all axes, including scale bars\n",
    "plt.rcParams.update({'font.size': 12})  # Increase font size\n",
    "xyarr[0,0].imshow(augmented_images[0][0].squeeze(), cmap='gray')\n",
    "xyarr[0,0].set_title('Original')\n",
    "xyarr[0,1].imshow(augmented_images[1][0].squeeze(), cmap='gray')\n",
    "xyarr[0,1].set_title('Random Noise')\n",
    "xyarr[0,2].imshow(augmented_images[2][0].squeeze(), cmap='gray')\n",
    "xyarr[0,2].set_title('Radial Noise')\n",
    "xyarr[0,3].imshow(augmented_images[3][0].squeeze(), cmap='gray')\n",
    "xyarr[0,3].set_title('Flip')    \n",
    "xyarr[1,0].imshow(augmented_images[4][0].squeeze(), cmap='gray')\n",
    "xyarr[1,0].set_title('Zoom')\n",
    "xyarr[1,1].imshow(augmented_images[5][0].squeeze(), cmap='gray')\n",
    "xyarr[1,1].set_title('Cutout')\n",
    "xyarr[1,2].imshow(augmented_images[6][0].squeeze(), cmap='gray')\n",
    "xyarr[1,2].set_title('Noise + Zoom')\n",
    "xyarr[1,3].imshow(augmented_images[7][0].squeeze(), cmap='gray')\n",
    "xyarr[1,3].set_title('Noise + Mask')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.4614 - accuracy: 0.8612 - val_loss: 0.2912 - val_accuracy: 0.9080\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2306 - accuracy: 0.9318 - val_loss: 0.2174 - val_accuracy: 0.9327\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1666 - accuracy: 0.9520 - val_loss: 0.2032 - val_accuracy: 0.9378\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1288 - accuracy: 0.9621 - val_loss: 0.2106 - val_accuracy: 0.9365\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1051 - accuracy: 0.9684 - val_loss: 0.1761 - val_accuracy: 0.9480\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0871 - accuracy: 0.9742 - val_loss: 0.2023 - val_accuracy: 0.9432\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0710 - accuracy: 0.9787 - val_loss: 0.2247 - val_accuracy: 0.9360\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0603 - accuracy: 0.9813 - val_loss: 0.2072 - val_accuracy: 0.9457\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0510 - accuracy: 0.9843 - val_loss: 0.2180 - val_accuracy: 0.9437\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0437 - accuracy: 0.9864 - val_loss: 0.2142 - val_accuracy: 0.9460\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0389 - accuracy: 0.9883 - val_loss: 0.2067 - val_accuracy: 0.9493\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0347 - accuracy: 0.9889 - val_loss: 0.2378 - val_accuracy: 0.9475\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 0.2399 - val_accuracy: 0.9473\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 0.2750 - val_accuracy: 0.9425\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.2815 - val_accuracy: 0.9407\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.4366 - accuracy: 0.8688 - val_loss: 0.2657 - val_accuracy: 0.9178\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 8s 4ms/step - loss: 0.2230 - accuracy: 0.9349 - val_loss: 0.1982 - val_accuracy: 0.9395\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1595 - accuracy: 0.9530 - val_loss: 0.1800 - val_accuracy: 0.9442\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.1229 - accuracy: 0.9642 - val_loss: 0.1838 - val_accuracy: 0.9438\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 8s 4ms/step - loss: 0.0969 - accuracy: 0.9714 - val_loss: 0.1681 - val_accuracy: 0.9497\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0768 - accuracy: 0.9774 - val_loss: 0.1793 - val_accuracy: 0.9455\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0621 - accuracy: 0.9814 - val_loss: 0.1800 - val_accuracy: 0.9480\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0502 - accuracy: 0.9852 - val_loss: 0.1824 - val_accuracy: 0.9513\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0396 - accuracy: 0.9884 - val_loss: 0.1892 - val_accuracy: 0.9527\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 8s 4ms/step - loss: 0.0354 - accuracy: 0.9894 - val_loss: 0.2043 - val_accuracy: 0.9487\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.2332 - val_accuracy: 0.9470\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.2562 - val_accuracy: 0.9433\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.2272 - val_accuracy: 0.9482\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.2515 - val_accuracy: 0.9485\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 8s 4ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.2619 - val_accuracy: 0.9470\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.8240 - accuracy: 0.7410 - val_loss: 0.6008 - val_accuracy: 0.8088\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.5240 - accuracy: 0.8369 - val_loss: 0.4783 - val_accuracy: 0.8458\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4508 - accuracy: 0.8589 - val_loss: 0.4550 - val_accuracy: 0.8607\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4069 - accuracy: 0.8742 - val_loss: 0.4044 - val_accuracy: 0.8720\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3799 - accuracy: 0.8830 - val_loss: 0.3975 - val_accuracy: 0.8777\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3634 - accuracy: 0.8874 - val_loss: 0.3952 - val_accuracy: 0.8763\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3427 - accuracy: 0.8951 - val_loss: 0.3890 - val_accuracy: 0.8763\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3296 - accuracy: 0.8989 - val_loss: 0.3730 - val_accuracy: 0.8837\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3162 - accuracy: 0.9008 - val_loss: 0.3951 - val_accuracy: 0.8733\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3063 - accuracy: 0.9046 - val_loss: 0.3662 - val_accuracy: 0.8888\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2998 - accuracy: 0.9083 - val_loss: 0.3881 - val_accuracy: 0.8812\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2915 - accuracy: 0.9105 - val_loss: 0.3613 - val_accuracy: 0.8885\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2859 - accuracy: 0.9107 - val_loss: 0.3634 - val_accuracy: 0.8898\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2767 - accuracy: 0.9151 - val_loss: 0.3536 - val_accuracy: 0.8933\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2712 - accuracy: 0.9157 - val_loss: 0.3447 - val_accuracy: 0.8908\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.7924 - accuracy: 0.7564 - val_loss: 0.3912 - val_accuracy: 0.8802\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.5105 - accuracy: 0.8431 - val_loss: 0.3104 - val_accuracy: 0.9020\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.4442 - accuracy: 0.8651 - val_loss: 0.2800 - val_accuracy: 0.9137\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 19s 11ms/step - loss: 0.4021 - accuracy: 0.8772 - val_loss: 0.2481 - val_accuracy: 0.9225\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.3770 - accuracy: 0.8845 - val_loss: 0.2426 - val_accuracy: 0.9268\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.3634 - accuracy: 0.8883 - val_loss: 0.2325 - val_accuracy: 0.9287\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.3443 - accuracy: 0.8944 - val_loss: 0.2214 - val_accuracy: 0.9313\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.3353 - accuracy: 0.8974 - val_loss: 0.2116 - val_accuracy: 0.9348\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 19s 11ms/step - loss: 0.3260 - accuracy: 0.8995 - val_loss: 0.2191 - val_accuracy: 0.9337\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.3147 - accuracy: 0.9040 - val_loss: 0.2079 - val_accuracy: 0.9337\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 13s 7ms/step - loss: 0.3105 - accuracy: 0.9057 - val_loss: 0.2068 - val_accuracy: 0.9342\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.3020 - accuracy: 0.9074 - val_loss: 0.2134 - val_accuracy: 0.9358\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.2953 - accuracy: 0.9104 - val_loss: 0.2014 - val_accuracy: 0.9390\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 19s 11ms/step - loss: 0.2912 - accuracy: 0.9111 - val_loss: 0.2098 - val_accuracy: 0.9332\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.2931 - accuracy: 0.9105 - val_loss: 0.2124 - val_accuracy: 0.9350\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 10s 5ms/step - loss: 0.6905 - accuracy: 0.7857 - val_loss: 0.3289 - val_accuracy: 0.8972\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.4375 - accuracy: 0.8627 - val_loss: 0.2722 - val_accuracy: 0.9150\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.3648 - accuracy: 0.8832 - val_loss: 0.2244 - val_accuracy: 0.9310\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.3290 - accuracy: 0.8957 - val_loss: 0.2085 - val_accuracy: 0.9382\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.3053 - accuracy: 0.9029 - val_loss: 0.2068 - val_accuracy: 0.9413\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.2814 - accuracy: 0.9099 - val_loss: 0.2066 - val_accuracy: 0.9393\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2714 - accuracy: 0.9137 - val_loss: 0.2087 - val_accuracy: 0.9362\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2610 - accuracy: 0.9174 - val_loss: 0.1844 - val_accuracy: 0.9502\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2461 - accuracy: 0.9206 - val_loss: 0.1843 - val_accuracy: 0.9485\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2405 - accuracy: 0.9238 - val_loss: 0.1783 - val_accuracy: 0.9480\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.2329 - accuracy: 0.9238 - val_loss: 0.1687 - val_accuracy: 0.9543\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.2338 - accuracy: 0.9254 - val_loss: 0.1830 - val_accuracy: 0.9502\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2236 - accuracy: 0.9276 - val_loss: 0.1875 - val_accuracy: 0.9503\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 8s 4ms/step - loss: 0.2208 - accuracy: 0.9285 - val_loss: 0.1800 - val_accuracy: 0.9512\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 8s 4ms/step - loss: 0.2164 - accuracy: 0.9313 - val_loss: 0.1919 - val_accuracy: 0.9487\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.4893 - accuracy: 0.8524 - val_loss: 0.2976 - val_accuracy: 0.9083\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.2630 - accuracy: 0.9207 - val_loss: 0.2389 - val_accuracy: 0.9263\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.2025 - accuracy: 0.9394 - val_loss: 0.1947 - val_accuracy: 0.9413\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 19s 11ms/step - loss: 0.1705 - accuracy: 0.9485 - val_loss: 0.1797 - val_accuracy: 0.9440\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.1483 - accuracy: 0.9551 - val_loss: 0.2083 - val_accuracy: 0.9375\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.1338 - accuracy: 0.9596 - val_loss: 0.1739 - val_accuracy: 0.9498\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.1203 - accuracy: 0.9634 - val_loss: 0.1892 - val_accuracy: 0.9465\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 17s 10ms/step - loss: 0.1107 - accuracy: 0.9657 - val_loss: 0.1904 - val_accuracy: 0.9470\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 24s 14ms/step - loss: 0.1018 - accuracy: 0.9671 - val_loss: 0.1965 - val_accuracy: 0.9450\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0939 - accuracy: 0.9712 - val_loss: 0.1748 - val_accuracy: 0.9520\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0889 - accuracy: 0.9718 - val_loss: 0.1755 - val_accuracy: 0.9530\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0825 - accuracy: 0.9732 - val_loss: 0.1858 - val_accuracy: 0.9503\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0780 - accuracy: 0.9754 - val_loss: 0.1904 - val_accuracy: 0.9533\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 23s 13ms/step - loss: 0.0761 - accuracy: 0.9759 - val_loss: 0.2000 - val_accuracy: 0.9457\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0708 - accuracy: 0.9773 - val_loss: 0.1975 - val_accuracy: 0.9548\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.8737 - accuracy: 0.7201 - val_loss: 0.5030 - val_accuracy: 0.8483\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 8s 4ms/step - loss: 0.6175 - accuracy: 0.7985 - val_loss: 0.4146 - val_accuracy: 0.8790\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.5374 - accuracy: 0.8274 - val_loss: 0.3855 - val_accuracy: 0.8872\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.4885 - accuracy: 0.8415 - val_loss: 0.3603 - val_accuracy: 0.8963\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.4704 - accuracy: 0.8463 - val_loss: 0.3402 - val_accuracy: 0.9040\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.4462 - accuracy: 0.8551 - val_loss: 0.3247 - val_accuracy: 0.9088\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.4283 - accuracy: 0.8613 - val_loss: 0.3676 - val_accuracy: 0.8990\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.4161 - accuracy: 0.8642 - val_loss: 0.3488 - val_accuracy: 0.9012\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.4066 - accuracy: 0.8657 - val_loss: 0.3517 - val_accuracy: 0.9030\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.3945 - accuracy: 0.8709 - val_loss: 0.3316 - val_accuracy: 0.9100\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.3828 - accuracy: 0.8753 - val_loss: 0.3543 - val_accuracy: 0.9060\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.3753 - accuracy: 0.8767 - val_loss: 0.3226 - val_accuracy: 0.9137\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.3664 - accuracy: 0.8815 - val_loss: 0.3598 - val_accuracy: 0.9092\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.3648 - accuracy: 0.8796 - val_loss: 0.3445 - val_accuracy: 0.9110\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.3617 - accuracy: 0.8805 - val_loss: 0.3353 - val_accuracy: 0.9132\n",
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4206 - accuracy: 0.8733 - val_loss: 0.2656 - val_accuracy: 0.9200\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2066 - accuracy: 0.9392 - val_loss: 0.2052 - val_accuracy: 0.9373\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1450 - accuracy: 0.9566 - val_loss: 0.1905 - val_accuracy: 0.9400\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1100 - accuracy: 0.9681 - val_loss: 0.1735 - val_accuracy: 0.9462\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0868 - accuracy: 0.9746 - val_loss: 0.1768 - val_accuracy: 0.9473\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0671 - accuracy: 0.9803 - val_loss: 0.1755 - val_accuracy: 0.9508\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0546 - accuracy: 0.9836 - val_loss: 0.1752 - val_accuracy: 0.9498\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0434 - accuracy: 0.9875 - val_loss: 0.1756 - val_accuracy: 0.9513\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.1860 - val_accuracy: 0.9523\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 0.2162 - val_accuracy: 0.9463\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0260 - accuracy: 0.9920 - val_loss: 0.2140 - val_accuracy: 0.9443\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.2217 - val_accuracy: 0.9468\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.2086 - val_accuracy: 0.9517\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.2603 - val_accuracy: 0.9452\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.2537 - val_accuracy: 0.9477\n"
     ]
    }
   ],
   "source": [
    "# Load json file\n",
    "with open(r'C:\\Users\\patri\\git\\DeepLearning\\DL-Project1\\testing\\MLP\\earlystopping\\results.json') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Load best model from h5 file # Change to best hyper parameters to train from scratch \n",
    "best_model_rand_noise = create_mlp(input_shape=input_shape, num_classes=num_classes, layer_units=results[0]['architecture'], activation=results[0]['activation'], learning_rate=results[0]['learning_rate'], optimizer=results[0]['optimizer'], dropout_rate=results[0]['dropout_rate'])\n",
    "best_model_radial_noise = create_mlp(input_shape=input_shape, num_classes=num_classes, layer_units=results[0]['architecture'], activation=results[0]['activation'], learning_rate=results[0]['learning_rate'], optimizer=results[0]['optimizer'], dropout_rate=results[0]['dropout_rate'])\n",
    "best_model_flip = create_mlp(input_shape=input_shape, num_classes=num_classes, layer_units=results[0]['architecture'], activation=results[0]['activation'], learning_rate=results[0]['learning_rate'], optimizer=results[0]['optimizer'], dropout_rate=results[0]['dropout_rate'])\n",
    "best_model_zoom = create_mlp(input_shape=input_shape, num_classes=num_classes, layer_units=results[0]['architecture'], activation=results[0]['activation'], learning_rate=results[0]['learning_rate'], optimizer=results[0]['optimizer'], dropout_rate=results[0]['dropout_rate'])\n",
    "best_model_mask = create_mlp(input_shape=input_shape, num_classes=num_classes, layer_units=results[0]['architecture'], activation=results[0]['activation'], learning_rate=results[0]['learning_rate'], optimizer=results[0]['optimizer'], dropout_rate=results[0]['dropout_rate'])\n",
    "best_model_rand_noise_zoom = create_mlp(input_shape=input_shape, num_classes=num_classes, layer_units=results[0]['architecture'], activation=results[0]['activation'], learning_rate=results[0]['learning_rate'], optimizer=results[0]['optimizer'], dropout_rate=results[0]['dropout_rate'])\n",
    "best_model_rand_noise_mask = create_mlp(input_shape=input_shape, num_classes=num_classes, layer_units=results[0]['architecture'], activation=results[0]['activation'], learning_rate=results[0]['learning_rate'], optimizer=results[0]['optimizer'], dropout_rate=results[0]['dropout_rate'])\n",
    "best_model_no_noise = create_mlp(input_shape=input_shape, num_classes=num_classes, layer_units=results[0]['architecture'], activation=results[0]['activation'], learning_rate=results[0]['learning_rate'], optimizer=results[0]['optimizer'], dropout_rate=results[0]['dropout_rate'])\n",
    "\n",
    "# Create a new ImageDataGenerator for validation data\n",
    "datagen_val = ImageDataGenerator()\n",
    "\n",
    "# Wrap the datagen with our custom generator\n",
    "train_generator_rand_noise = datagen_rand_noise.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_radial_noise = datagen_radial_noise.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_flip = datagen_flip.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_zoom = datagen_zoom.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_mask = datagen_mask.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_rand_noise_zoom = datagen_rand_noise_zoom.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_rand_noise_mask = datagen_rand_noise_mask.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_no_noise = datagen_no_noise.flow(x_train, y_train, batch_size=32)\n",
    "val_generator = datagen_val.flow(x_val, y_val, batch_size=32)\n",
    "\n",
    "# Train the model with custom augmentation\n",
    "augmentation_loss_df = pd.DataFrame()\n",
    "augmentation_accuracy_df = pd.DataFrame()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "epochs=15\n",
    "\n",
    "# Random noise\n",
    "history_rand_noise = best_model_rand_noise.fit(train_generator_rand_noise,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_generator,  \n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_rand_noise.history['val_loss'][-1]\n",
    "last_val_accuracy = history_rand_noise.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_rand_noise.history['val_loss']), 16):\n",
    "    history_rand_noise.history['val_loss'].append(last_val_loss)\n",
    "    history_rand_noise.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"rand_noise\"] = history_rand_noise.history['val_loss']\n",
    "augmentation_accuracy_df[f\"rand_noise\"] = history_rand_noise.history['val_accuracy']\n",
    "\n",
    "# Radial noise\n",
    "history_radial_noise = best_model_radial_noise.fit(train_generator_radial_noise,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_generator,  \n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_radial_noise.history['val_loss'][-1]\n",
    "last_val_accuracy = history_radial_noise.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_radial_noise.history['val_loss']), 16):\n",
    "    history_radial_noise.history['val_loss'].append(last_val_loss)\n",
    "    history_radial_noise.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"radial_noise\"] = history_radial_noise.history['val_loss']\n",
    "augmentation_accuracy_df[f\"radial_noise\"] = history_radial_noise.history['val_accuracy']\n",
    "\n",
    "\n",
    "# Flip\n",
    "history_flip = best_model_flip.fit(train_generator_flip,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_flip.history['val_loss'][-1]\n",
    "last_val_accuracy = history_flip.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_flip.history['val_loss']), 16):\n",
    "    history_flip.history['val_loss'].append(last_val_loss)\n",
    "    history_flip.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"flip\"] = history_flip.history['val_loss']\n",
    "augmentation_accuracy_df[f\"flip\"] = history_flip.history['val_accuracy']\n",
    "\n",
    "# Zoom\n",
    "history_zoom = best_model_zoom.fit(train_generator_zoom,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_zoom.history['val_loss'][-1]\n",
    "last_val_accuracy = history_zoom.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_zoom.history['val_loss']), 16):\n",
    "    history_zoom.history['val_loss'].append(last_val_loss)\n",
    "    history_zoom.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"zoom\"] = history_zoom.history['val_loss']\n",
    "augmentation_accuracy_df[f\"zoom\"] = history_zoom.history['val_accuracy']\n",
    "\n",
    "# Mask\n",
    "history_mask = best_model_mask.fit(train_generator_mask,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_mask.history['val_loss'][-1]\n",
    "last_val_accuracy = history_mask.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_mask.history['val_loss']), 16):\n",
    "    history_mask.history['val_loss'].append(last_val_loss)\n",
    "    history_mask.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"mask\"] = history_mask.history['val_loss']\n",
    "augmentation_accuracy_df[f\"mask\"] = history_mask.history['val_accuracy']\n",
    "\n",
    "# Rand noise and zoom\n",
    "history_rand_noise_zoom = best_model_rand_noise_zoom.fit(train_generator_rand_noise_zoom,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_rand_noise_zoom.history['val_loss'][-1]\n",
    "last_val_accuracy = history_rand_noise_zoom.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_rand_noise_zoom.history['val_loss']), 16):\n",
    "    history_rand_noise_zoom.history['val_loss'].append(last_val_loss)\n",
    "    history_rand_noise_zoom.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"rand_noise_zoom\"] = history_rand_noise_zoom.history['val_loss']\n",
    "augmentation_accuracy_df[f\"rand_noise_zoom\"] = history_rand_noise_zoom.history['val_accuracy']\n",
    "\n",
    "# Random noise and mask\n",
    "history_rand_noise_mask = best_model_rand_noise_mask.fit(train_generator_rand_noise_mask,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_rand_noise_mask.history['val_loss'][-1]\n",
    "last_val_accuracy = history_rand_noise_mask.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_rand_noise_mask.history['val_loss']), 16):\n",
    "    history_rand_noise_mask.history['val_loss'].append(last_val_loss)\n",
    "    history_rand_noise_mask.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"rand_noise_mask\"] = history_rand_noise_mask.history['val_loss']\n",
    "augmentation_accuracy_df[f\"rand_noise_mask\"] = history_rand_noise_mask.history['val_accuracy']\n",
    "\n",
    "# No noise\n",
    "history_no_noise = best_model_no_noise.fit(train_generator_no_noise,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "last_val_loss = history_no_noise.history['val_loss'][-1]\n",
    "last_val_accuracy = history_no_noise.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_no_noise.history['val_loss']), 16):\n",
    "    history_no_noise.history['val_loss'].append(last_val_loss)\n",
    "    history_no_noise.history['val_accuracy'].append(last_val_accuracy)\n",
    "augmentation_loss_df[f\"no_noise\"] = history_no_noise.history['val_loss']\n",
    "augmentation_accuracy_df[f\"no_noise\"] = history_no_noise.history['val_accuracy']\n",
    "\n",
    "# Save the dataframes to CSV files\n",
    "augmentation_loss_df.to_csv('augmentation_loss.csv', index=False)\n",
    "augmentation_accuracy_df.to_csv('augmentation_accuracy.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand noise test accuracy: 0.8755\n",
      "Rand noise test loss: 0.7229\n",
      "Radial noise test accuracy: 0.8804\n",
      "Radial noise test loss: 0.6837\n",
      "Flip test accuracy: 0.7892\n",
      "Flip test loss: 0.7381\n",
      "Zoom test accuracy: 0.8650\n",
      "Zoom test loss: 0.4711\n",
      "Mask test accuracy: 0.8823\n",
      "Mask test loss: 0.5029\n",
      "Rand noise and zoom test accuracy: 0.8940\n",
      "Rand noise and zoom test loss: 0.5300\n",
      "Rand noise and mask test accuracy: 0.8257\n",
      "Rand noise and mask test loss: 0.7325\n",
      "No noise test accuracy: 0.8915\n",
      "No noise test loss: 0.6355\n",
      "\n",
      "Best accuracy: 0.8940 with augmentation: rand_noise_zoom\n"
     ]
    }
   ],
   "source": [
    "rand_noise_loss, rand_noise_accuracy = best_model_rand_noise.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Rand noise test accuracy: {rand_noise_accuracy:.4f}\")\n",
    "print(f\"Rand noise test loss: {rand_noise_loss:.4f}\")\n",
    "radial_noise_loss, radial_noise_accuracy = best_model_radial_noise.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Radial noise test accuracy: {radial_noise_accuracy:.4f}\")\n",
    "print(f\"Radial noise test loss: {radial_noise_loss:.4f}\")\n",
    "flip_loss, flip_accuracy = best_model_flip.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Flip test accuracy: {flip_accuracy:.4f}\")\n",
    "print(f\"Flip test loss: {flip_loss:.4f}\")\n",
    "zoom_loss, zoom_accuracy = best_model_zoom.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Zoom test accuracy: {zoom_accuracy:.4f}\")\n",
    "print(f\"Zoom test loss: {zoom_loss:.4f}\")\n",
    "mask_loss, mask_accuracy = best_model_mask.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Mask test accuracy: {mask_accuracy:.4f}\")\n",
    "print(f\"Mask test loss: {mask_loss:.4f}\")\n",
    "rand_noise_zoom_loss, rand_noise_zoom_accuracy = best_model_rand_noise_zoom.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Rand noise and zoom test accuracy: {rand_noise_zoom_accuracy:.4f}\")\n",
    "print(f\"Rand noise and zoom test loss: {rand_noise_zoom_loss:.4f}\")\n",
    "rand_noise_mask_loss, rand_noise_mask_accuracy = best_model_rand_noise_mask.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Rand noise and mask test accuracy: {rand_noise_mask_accuracy:.4f}\")\n",
    "print(f\"Rand noise and mask test loss: {rand_noise_mask_loss:.4f}\")\n",
    "no_noise_loss, no_noise_accuracy = best_model_no_noise.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"No noise test accuracy: {no_noise_accuracy:.4f}\")\n",
    "print(f\"No noise test loss: {no_noise_loss:.4f}\") \n",
    "\n",
    "# List of accuracies where elements are tupels of the name of the augmentation and the accuracy\n",
    "accuracies = [('rand_noise', rand_noise_accuracy), ('radial_noise', radial_noise_accuracy), ('flip', flip_accuracy), ('zoom', zoom_accuracy), ('mask', mask_accuracy), ('rand_noise_zoom', rand_noise_zoom_accuracy), ('rand_noise_mask', rand_noise_mask_accuracy), ('no_noise', no_noise_accuracy)]\n",
    "\n",
    "# Get best accuracy\n",
    "best_accuracy = max(accuracies, key=lambda x: x[1])\n",
    "print(f\"\\nBest accuracy: {best_accuracy[1]:.4f} with augmentation: {best_accuracy[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 963us/step\n",
      "313/313 [==============================] - 0s 995us/step\n",
      "313/313 [==============================] - 0s 976us/step\n",
      "313/313 [==============================] - 0s 995us/step\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "# List of models and their names\n",
    "models = [\n",
    "    (best_model_rand_noise, \"Random Noise\"),\n",
    "    (best_model_radial_noise, \"Radial Noise\"),\n",
    "    (best_model_flip, \"Flip\"),\n",
    "    (best_model_zoom, \"Zoom\"),\n",
    "    (best_model_mask, \"Mask\"),\n",
    "    (best_model_rand_noise_zoom, \"Random Noise + Zoom\"),\n",
    "    (best_model_rand_noise_mask, \"Random Noise + Mask\"),\n",
    "    (best_model_no_noise, \"No Noise\")\n",
    "]\n",
    "\n",
    "# Create and save confusion matrices for each model\n",
    "for model, name in models:\n",
    "    # Predictions on the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Confusion matrix\n",
    "    confusion = confusion_matrix(y_test, y_pred_class)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    disp.plot(ax=ax)\n",
    "    plt.title(f'Confusion Matrix for {name}')\n",
    "    \n",
    "    # Save the figure\n",
    "    now = datetime.datetime.now()\n",
    "    plt.savefig(f'Aug_CMs/confusion_matrix_{name.replace(\" \", \"_\").lower()}_{now.strftime(\"%Y-%m-%d\")}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1688/1688 [==============================] - 8s 4ms/step - loss: 0.1206 - accuracy: 0.9593 - val_loss: 0.2215 - val_accuracy: 0.9543\n",
      "Epoch 2/100\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1242 - accuracy: 0.9581 - val_loss: 0.2145 - val_accuracy: 0.9540\n",
      "Epoch 3/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1194 - accuracy: 0.9596 - val_loss: 0.2196 - val_accuracy: 0.9567\n",
      "Epoch 4/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1245 - accuracy: 0.9584 - val_loss: 0.2149 - val_accuracy: 0.9553\n",
      "Epoch 5/100\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1216 - accuracy: 0.9588 - val_loss: 0.2296 - val_accuracy: 0.9535\n",
      "Epoch 6/100\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1232 - accuracy: 0.9583 - val_loss: 0.2188 - val_accuracy: 0.9540\n",
      "Epoch 7/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1225 - accuracy: 0.9595 - val_loss: 0.2132 - val_accuracy: 0.9532\n",
      "Epoch 8/100\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1229 - accuracy: 0.9573 - val_loss: 0.2197 - val_accuracy: 0.9552\n",
      "Epoch 9/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1207 - accuracy: 0.9594 - val_loss: 0.2253 - val_accuracy: 0.9542\n",
      "Epoch 10/100\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1200 - accuracy: 0.9589 - val_loss: 0.2109 - val_accuracy: 0.9560\n",
      "Epoch 11/100\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1243 - accuracy: 0.9579 - val_loss: 0.2312 - val_accuracy: 0.9538\n",
      "Epoch 12/100\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1224 - accuracy: 0.9585 - val_loss: 0.2291 - val_accuracy: 0.9523\n",
      "Epoch 13/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1221 - accuracy: 0.9590 - val_loss: 0.2198 - val_accuracy: 0.9528\n",
      "Epoch 14/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1157 - accuracy: 0.9611 - val_loss: 0.2384 - val_accuracy: 0.9510\n",
      "Epoch 15/100\n",
      "1688/1688 [==============================] - 8s 4ms/step - loss: 0.1225 - accuracy: 0.9591 - val_loss: 0.2390 - val_accuracy: 0.9532\n",
      "Epoch 1/100\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.4387 - val_accuracy: 0.9537\n",
      "Epoch 2/100\n",
      "1688/1688 [==============================] - 20s 12ms/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.4274 - val_accuracy: 0.9545\n",
      "Epoch 3/100\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.4391 - val_accuracy: 0.9557\n",
      "Epoch 4/100\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0233 - accuracy: 0.9932 - val_loss: 0.4469 - val_accuracy: 0.9525\n",
      "Epoch 5/100\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.4663 - val_accuracy: 0.9492\n",
      "Epoch 6/100\n",
      "1688/1688 [==============================] - 21s 12ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 0.4805 - val_accuracy: 0.9472\n",
      "Epoch 7/100\n",
      "1688/1688 [==============================] - 22s 13ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.4436 - val_accuracy: 0.9562\n",
      "Mask long test accuracy: 0.8915\n",
      "Mask long test loss: 0.6573\n",
      "Rand noise and zoom long test accuracy: 0.8956\n",
      "Rand noise and zoom long test loss: 1.1982\n"
     ]
    }
   ],
   "source": [
    "# Update the number of epochs\n",
    "epochs = 100\n",
    "\n",
    "# Create new DataFrames for the results\n",
    "new_augmentation_loss_df = pd.DataFrame()\n",
    "new_augmentation_accuracy_df = pd.DataFrame()\n",
    "\n",
    "# Create a new ImageDataGenerator for validation data\n",
    "datagen_val = ImageDataGenerator()\n",
    "\n",
    "# Wrap the datagen with our custom generator\n",
    "train_generator_mask = datagen_mask.flow(x_train, y_train, batch_size=32)\n",
    "train_generator_rand_noise_zoom = datagen_rand_noise_zoom.flow(x_train, y_train, batch_size=32)\n",
    "val_generator = datagen_val.flow(x_val, y_val, batch_size=32)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Mask\n",
    "history_mask_long = best_model_mask.fit(train_generator_mask,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=early_stopping\n",
    "                        )\n",
    "last_val_loss = history_mask_long.history['val_loss'][-1]\n",
    "last_val_accuracy = history_mask_long.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_mask_long.history['val_loss']), 101):\n",
    "    history_mask_long.history['val_loss'].append(last_val_loss)\n",
    "    history_mask_long.history['val_accuracy'].append(last_val_accuracy)\n",
    "new_augmentation_loss_df[f\"mask\"] = history_mask_long.history['val_loss']\n",
    "new_augmentation_accuracy_df[f\"mask\"] = history_mask_long.history['val_accuracy']\n",
    "\n",
    "# Rand noise and zoom\n",
    "history_rand_noise_zoom_long = best_model_rand_noise_zoom.fit(train_generator_rand_noise_zoom,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_generator,\n",
    "                        verbose=1,\n",
    "                        callbacks=early_stopping\n",
    "                        )\n",
    "last_val_loss = history_rand_noise_zoom_long.history['val_loss'][-1]\n",
    "last_val_accuracy = history_rand_noise_zoom_long.history['val_accuracy'][-1]\n",
    "for _ in range(len(history_rand_noise_zoom_long.history['val_loss']), 101):\n",
    "    history_rand_noise_zoom_long.history['val_loss'].append(last_val_loss)\n",
    "    history_rand_noise_zoom_long.history['val_accuracy'].append(last_val_accuracy)\n",
    "new_augmentation_loss_df[f\"rand_noise_zoom\"] = history_rand_noise_zoom_long.history['val_loss']\n",
    "new_augmentation_accuracy_df[f\"rand_noise_zoom\"] = history_rand_noise_zoom_long.history['val_accuracy']\n",
    "\n",
    "# Calculate the test accuracy for each model\n",
    "mask_long_loss, mask_long_accuracy = best_model_mask.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Mask long test accuracy: {mask_long_accuracy:.4f}\")\n",
    "print(f\"Mask long test loss: {mask_long_loss:.4f}\")\n",
    "rand_noise_zoom_long_loss, rand_noise_zoom_long_accuracy = best_model_rand_noise_zoom.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Rand noise and zoom long test accuracy: {rand_noise_zoom_long_accuracy:.4f}\")\n",
    "print(f\"Rand noise and zoom long test loss: {rand_noise_zoom_long_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the new DataFrames to CSV files\n",
    "new_augmentation_loss_df.to_csv('new_augmentation_loss.csv', index=False)\n",
    "new_augmentation_accuracy_df.to_csv('new_augmentation_accuracy.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eel4930",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
